{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment3_300144160_partB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNY/Yd+EfXDp1NqNM34IADk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarmanBhutani/ML_projects/blob/main/Assignment3_300144160_partB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPTvTNQ3bJy"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9lKuM49AzS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import re\n",
        "import matplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve,auc,plot_roc_curve\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BaseNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#pip install xgboost\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peuqqDca-xxr",
        "outputId": "a557bf5d-c1f9-4d94-f58a-e759fd559549"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960Sm7lZ3p6b"
      },
      "source": [
        "tweets_df = pd.read_csv(\"Covid_train_data.csv\", encoding='latin-1')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "k0GULvT_3p3X",
        "outputId": "9f232915-7c3b-4baf-b328-89bea1b44c7d"
      },
      "source": [
        "tweets_df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0      3799  ...             Neutral\n",
              "1      3800  ...            Positive\n",
              "2      3801  ...            Positive\n",
              "3      3802  ...            Positive\n",
              "4      3803  ...  Extremely Negative\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGW5Mo8E8l0J",
        "outputId": "3eb94ffa-9ded-4895-e0e7-61c1aaa939ef"
      },
      "source": [
        "len(tweets_df)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbQoVE1h3p0c",
        "outputId": "eaaf1981-1332-4cee-dc21-3086de9754fd"
      },
      "source": [
        "# Print the value counts of Country column\n",
        "Location_count=tweets_df[\"Location\"].value_counts()\n",
        "Location_count"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "London                 540\n",
              "United States          528\n",
              "London, England        520\n",
              "New York, NY           395\n",
              "Washington, DC         373\n",
              "                      ... \n",
              "El Dorado Hills, CA      1\n",
              "Sonoma County, CA        1\n",
              "Evanston, Ill.           1\n",
              "Always Hungry, USA       1\n",
              "????, ????? ????         1\n",
              "Name: Location, Length: 12220, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1mM4vPs3pxd",
        "outputId": "77d5f567-38b3-4085-f3bb-ba1bc88ba35d"
      },
      "source": [
        "# Print the value counts of Sentiments column\n",
        "Sentiments_count=tweets_df[\"Sentiment\"].value_counts()\n",
        "Sentiments_count"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive              11422\n",
              "Negative               9917\n",
              "Neutral                7713\n",
              "Extremely Positive     6624\n",
              "Extremely Negative     5481\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "DS5UaTIb-Kw-",
        "outputId": "428a4b3d-2d28-4092-e8ef-5faaabd75ab1"
      },
      "source": [
        "# Display the first five rows\n",
        "display(tweets_df.head())\n",
        "# Print the summary statistics\n",
        "print(tweets_df.describe())\n",
        "# Print the info\n",
        "print(tweets_df.info())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0      3799  ...             Neutral\n",
              "1      3800  ...            Positive\n",
              "2      3801  ...            Positive\n",
              "3      3802  ...            Positive\n",
              "4      3803  ...  Extremely Negative\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "           UserName    ScreenName\n",
            "count  41157.000000  41157.000000\n",
            "mean   24377.000000  69329.000000\n",
            "std    11881.146851  11881.146851\n",
            "min     3799.000000  48751.000000\n",
            "25%    14088.000000  59040.000000\n",
            "50%    24377.000000  69329.000000\n",
            "75%    34666.000000  79618.000000\n",
            "max    44955.000000  89907.000000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41157 entries, 0 to 41156\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   UserName       41157 non-null  int64 \n",
            " 1   ScreenName     41157 non-null  int64 \n",
            " 2   Location       32567 non-null  object\n",
            " 3   TweetAt        41157 non-null  object\n",
            " 4   OriginalTweet  41157 non-null  object\n",
            " 5   Sentiment      41157 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 1.9+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "doDTTIpO-gMQ",
        "outputId": "53233de4-f590-4ea0-add9-16cf3a9e7300"
      },
      "source": [
        "def process_tweets(tweet):\n",
        "    \n",
        "    # Remove links\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove mentions and hashtag\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "    \n",
        "    # Tokenize the words\n",
        "    tokenized = word_tokenize(tweet)\n",
        "\n",
        "    # Remove the stop words\n",
        "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \n",
        "\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenized = [lemmatizer.lemmatize(token, pos='a') for token in tokenized]\n",
        "\n",
        "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
        "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\n",
        "    \n",
        "    return tokenized\n",
        "    \n",
        "# Call the function and store the result into a new column\n",
        "tweets_df[\"Processed\"] = tweets_df[\"OriginalTweet\"].str.lower().apply(process_tweets)\n",
        "\n",
        "# Print the first fifteen rows of Processed\n",
        "display(tweets_df[[\"Processed\"]].head(15))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ready, supermarket, outbreak, paranoid, food,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[news, first, confirmed, case, came, sullivan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[cashier, grocery, store, sharing, insights, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[supermarket, today, buy, toilet, paper, rebel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[due, retail, store, classroom, atlanta, open,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[corona, prevention, stop, buy, things, cash, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[month, crowding, supermarkets, restaurants, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[due, situation, increased, demand, food, prod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[horningsea, caring, community, look, less, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[need, stock, food, amazon, deliver, whatever,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[adara, releases, resource, center, travel, br...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Processed\n",
              "0                                                  []\n",
              "1   [advice, talk, neighbours, family, exchange, p...\n",
              "2   [coronavirus, australia, woolworths, give, eld...\n",
              "3   [food, stock, one, empty, please, panic, enoug...\n",
              "4   [ready, supermarket, outbreak, paranoid, food,...\n",
              "5   [news, first, confirmed, case, came, sullivan,...\n",
              "6   [cashier, grocery, store, sharing, insights, p...\n",
              "7   [supermarket, today, buy, toilet, paper, rebel...\n",
              "8   [due, retail, store, classroom, atlanta, open,...\n",
              "9   [corona, prevention, stop, buy, things, cash, ...\n",
              "10  [month, crowding, supermarkets, restaurants, h...\n",
              "11  [due, situation, increased, demand, food, prod...\n",
              "12  [horningsea, caring, community, look, less, ca...\n",
              "13  [need, stock, food, amazon, deliver, whatever,...\n",
              "14  [adara, releases, resource, center, travel, br..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "NhWnqxcx-gIH",
        "outputId": "b493f11e-062e-411f-a9f6-ff33f6987621"
      },
      "source": [
        "# Get the tweet lengths\n",
        "tweets_df[\"Length\"] = tweets_df[\"OriginalTweet\"].str.len()\n",
        "# Get the number of words in tweets\n",
        "tweets_df[\"Words\"] = tweets_df[\"OriginalTweet\"].str.split().str.len()\n",
        "# Display the new columns\n",
        "display(tweets_df[[\"Length\", \"Words\"]])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>237</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>310</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>102</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>138</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>136</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>111</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>255</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Length  Words\n",
              "0         111      8\n",
              "1         237     38\n",
              "2         131     14\n",
              "3         306     42\n",
              "4         310     40\n",
              "...       ...    ...\n",
              "41152     102     12\n",
              "41153     138     23\n",
              "41154     136     18\n",
              "41155     111     18\n",
              "41156     255     46\n",
              "\n",
              "[41157 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FCu7S82_JFI"
      },
      "source": [
        "tweets_df[\"Location\"].fillna(\"unknown\", inplace=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "VPlcoKB-_JBw",
        "outputId": "4ff7cbad-16a6-40af-97f2-929aad72097b"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Initialize a Tf-idf Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "# Fit and transform the vectorizer\n",
        "tfidf_matrix = vectorizer.fit_transform([' '.join(l) for l in tweets_df[\"Processed\"]])\n",
        "# Let's see what we have\n",
        "display(tfidf_matrix)\n",
        "# Create a DataFrame for tf-idf vectors and display the first rows\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())\n",
        "display(tfidf_df)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<41157x100 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 186001 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>amid</th>\n",
              "      <th>amp</th>\n",
              "      <th>back</th>\n",
              "      <th>business</th>\n",
              "      <th>buy</th>\n",
              "      <th>buying</th>\n",
              "      <th>consumer</th>\n",
              "      <th>coronavirus</th>\n",
              "      <th>could</th>\n",
              "      <th>covid</th>\n",
              "      <th>crisis</th>\n",
              "      <th>customers</th>\n",
              "      <th>day</th>\n",
              "      <th>delivery</th>\n",
              "      <th>demand</th>\n",
              "      <th>due</th>\n",
              "      <th>employees</th>\n",
              "      <th>essential</th>\n",
              "      <th>even</th>\n",
              "      <th>every</th>\n",
              "      <th>everyone</th>\n",
              "      <th>first</th>\n",
              "      <th>food</th>\n",
              "      <th>get</th>\n",
              "      <th>going</th>\n",
              "      <th>good</th>\n",
              "      <th>government</th>\n",
              "      <th>grocery</th>\n",
              "      <th>hand</th>\n",
              "      <th>health</th>\n",
              "      <th>help</th>\n",
              "      <th>high</th>\n",
              "      <th>home</th>\n",
              "      <th>impact</th>\n",
              "      <th>items</th>\n",
              "      <th>keep</th>\n",
              "      <th>know</th>\n",
              "      <th>like</th>\n",
              "      <th>local</th>\n",
              "      <th>...</th>\n",
              "      <th>prices</th>\n",
              "      <th>products</th>\n",
              "      <th>retail</th>\n",
              "      <th>right</th>\n",
              "      <th>safe</th>\n",
              "      <th>sanitizer</th>\n",
              "      <th>see</th>\n",
              "      <th>shelves</th>\n",
              "      <th>shop</th>\n",
              "      <th>shopping</th>\n",
              "      <th>social</th>\n",
              "      <th>socialdistancing</th>\n",
              "      <th>spread</th>\n",
              "      <th>staff</th>\n",
              "      <th>stay</th>\n",
              "      <th>still</th>\n",
              "      <th>stock</th>\n",
              "      <th>stop</th>\n",
              "      <th>store</th>\n",
              "      <th>stores</th>\n",
              "      <th>supermarket</th>\n",
              "      <th>supplies</th>\n",
              "      <th>supply</th>\n",
              "      <th>take</th>\n",
              "      <th>thank</th>\n",
              "      <th>think</th>\n",
              "      <th>time</th>\n",
              "      <th>today</th>\n",
              "      <th>toilet</th>\n",
              "      <th>toiletpaper</th>\n",
              "      <th>use</th>\n",
              "      <th>via</th>\n",
              "      <th>virus</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>work</th>\n",
              "      <th>workers</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>would</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.702164</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.617436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.453185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.287786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.551151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.305863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.292708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.549792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.503874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.558534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463867</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442128</td>\n",
              "      <td>0.428688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.554381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.598742</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.578075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.423872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279045</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.502163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       also      amid  amp  back  ...  workers  working  world  would\n",
              "0       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "1       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "2       0.0  0.617436  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "3       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "4       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "...     ...       ...  ...   ...  ...      ...      ...    ...    ...\n",
              "41152   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41153   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41154   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41155   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41156   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "\n",
              "[41157 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "fsCdNVBd_I-2",
        "outputId": "53405856-3f6d-4752-ba19-bce28d12e042"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "tweets_df[\"Label_enc\"] = le.fit_transform(tweets_df[\"Sentiment\"])\n",
        "# Display the encoded labels\n",
        "display(tweets_df[[\"Label_enc\"]].head())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label_enc\n",
              "0          3\n",
              "1          4\n",
              "2          4\n",
              "3          4\n",
              "4          0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1QklKxJ-gDh"
      },
      "source": [
        "X = tweets_df['Processed']\n",
        "y = tweets_df[\"Label_enc\"]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G78N-BDVBwS2"
      },
      "source": [
        "tweets_test = pd.read_csv(\"Covid_test_data.csv\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5ONWzfSoBgRJ",
        "outputId": "c6c6c68d-9660-4907-9cdb-054caca4946f"
      },
      "source": [
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "tweets_test[\"Label_enc\"] = le.fit_transform(tweets_test[\"Sentiment\"])\n",
        "# Display the encoded labels\n",
        "display(tweets_test[[\"Label_enc\"]].head())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label_enc\n",
              "0          0\n",
              "1          4\n",
              "2          1\n",
              "3          2\n",
              "4          3"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "VUVRASgNCXLk",
        "outputId": "1947576a-fb65-45e8-cadc-353acbab4984"
      },
      "source": [
        "def process_tweets(tweet):\n",
        "    \n",
        "    # Remove links\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove mentions and hashtag\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "    \n",
        "    # Tokenize the words\n",
        "    tokenized = word_tokenize(tweet)\n",
        "\n",
        "    # Remove the stop words\n",
        "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \n",
        "\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenized = [lemmatizer.lemmatize(token, pos='a') for token in tokenized]\n",
        "\n",
        "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
        "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\n",
        "    \n",
        "    return tokenized\n",
        "    \n",
        "# Call the function and store the result into a new column\n",
        "tweets_test[\"Processed\"] = tweets_test[\"OriginalTweet\"].str.lower().apply(process_tweets)\n",
        "\n",
        "# Print the first fifteen rows of Processed\n",
        "display(tweets_test[[\"Processed\"]].head(15))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[trending, new, yorkers, encounter, empty, sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[could, find, hand, sanitizer, fred, meyer, tu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[find, protect, loved, ones, coronavirus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[panic, buying, hits, newyork, city, anxious, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[toiletpaper, dunnypaper, coronavirus, coronav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[remember, last, time, paid, gallon, regular, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[voting, age, coronavirus, hand, sanitizer, su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[stop, without, protecting, healthworkers, pri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[twitter, pharmacist, sell, hand, sanitizer, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[anyone, supermarket, last, days, went, normal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[best, quality, couches, unbelievably, low, pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[beware, counterfeits, trying, sell, fake, mas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[panic, food, buying, germany, due, coronaviru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[went, grocery, store, turns, cleaning, suppli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[busy, watching, election, returns, bracing, o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Processed\n",
              "0   [trending, new, yorkers, encounter, empty, sup...\n",
              "1   [could, find, hand, sanitizer, fred, meyer, tu...\n",
              "2           [find, protect, loved, ones, coronavirus]\n",
              "3   [panic, buying, hits, newyork, city, anxious, ...\n",
              "4   [toiletpaper, dunnypaper, coronavirus, coronav...\n",
              "5   [remember, last, time, paid, gallon, regular, ...\n",
              "6   [voting, age, coronavirus, hand, sanitizer, su...\n",
              "7   [stop, without, protecting, healthworkers, pri...\n",
              "8   [twitter, pharmacist, sell, hand, sanitizer, l...\n",
              "9   [anyone, supermarket, last, days, went, normal...\n",
              "10  [best, quality, couches, unbelievably, low, pr...\n",
              "11  [beware, counterfeits, trying, sell, fake, mas...\n",
              "12  [panic, food, buying, germany, due, coronaviru...\n",
              "13  [went, grocery, store, turns, cleaning, suppli...\n",
              "14  [busy, watching, election, returns, bracing, o..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUp4yzFgCL47"
      },
      "source": [
        "X_test = tweets_test['Processed']\n",
        "y_test = tweets_test[\"Label_enc\"]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cImIXQL45aJZ",
        "outputId": "d3e4e422-a8a1-43cf-dbbe-a227f3aa9832"
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYEEn5mE57OH"
      },
      "source": [
        "model_vectorizer = TfidfVectorizer()\n",
        "# First fit the vectorizer with our training set\n",
        "tfidf_train = vectorizer.fit_transform([' '.join(l) for l in X])\n",
        "# Now we can fit our test data with the same vectorizer\n",
        "tfidf_test = vectorizer.transform([' '.join(l) for l in X_test])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnO0Vf0q6ITf"
      },
      "source": [
        "from functools import reduce"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKm5QhE6245d",
        "outputId": "ed49fd60-e5fe-4b38-82c7-88f51d1955a2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def generate_rf(X_train, y_train, X_test, y_test):\n",
        "    rf = RandomForestClassifier(n_estimators=5, min_samples_leaf=3)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print (\"rf score \", rf.score(X_test, y_test))\n",
        "    return rf\n",
        "\n",
        "def combine_rfs(rf_a, rf_b):\n",
        "    rf_a.estimators_ += rf_b.estimators_\n",
        "    rf_a.n_estimators = len(rf_a.estimators_)\n",
        "    return rf_a\n",
        "\n",
        "\n",
        "# in the line below, we create 10 random forest classifier models\n",
        "rfs = [generate_rf(tfidf_train, y, tfidf_test, y_test)]\n",
        "# in this step below, we combine the list of random forest models into one giant model\n",
        "rf_combined = reduce(combine_rfs, rfs)\n",
        "# the combined model scores better than *most* of the component models\n",
        "print (\"rf combined score\", rf_combined.score(tfidf_test, y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rf score  0.3504476040021064\n",
            "rf combined score 0.3504476040021064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwAmYCEo6PCr",
        "outputId": "c50bd39c-08c7-4206-df81-15a3cef694a2"
      },
      "source": [
        "# Print the accuracy score\n",
        "best_accuracy = cross_val_score(rf_combined, tfidf_test, y_test, cv=10, scoring='accuracy').max()\n",
        "print(\"Accuracy:\",best_accuracy)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3447368421052632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNMuJfrU5krb"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in  X.str.join(' ')]\n",
        "\n",
        "feature_size = 100\n",
        "window_context = 10  # Context window size                                                                                    \n",
        "min_word_count = 1   # Minimum word count, i.e., words > this are going to be included in the model                        \n",
        "sample = 1e-3        # Downsample setting for frequent words\n",
        "\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, \n",
        "                              window=window_context, min_count = min_word_count,\n",
        "                              sample=sample)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QR97FZV6CxP",
        "outputId": "260ee262-53b3-44a2-9809-6092883aa2d2"
      },
      "source": [
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    nwords = 0.\n",
        "    \n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vector = np.add(feature_vector, model[word])\n",
        "    \n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "        \n",
        "    return feature_vector\n",
        "   \n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\n",
        "                                             num_features=feature_size)\n",
        "X_train_wordvec = pd.DataFrame(w2v_feature_array)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZz4cZZy8JUU"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in  X_test.str.join(' ')]\n",
        "\n",
        "feature_size = 100\n",
        "window_context = 10  # Context window size                                                                                    \n",
        "min_word_count = 1   # Minimum word count, i.e., words > this are going to be included in the model                        \n",
        "sample = 1e-3        # Downsample setting for frequent words\n",
        "\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, \n",
        "                              window=window_context, min_count = min_word_count,\n",
        "                              sample=sample)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A5XK9Qp8Kwk",
        "outputId": "7eb13ead-681c-41ff-8512-401646df4c4b"
      },
      "source": [
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    nwords = 0.\n",
        "    \n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vector = np.add(feature_vector, model[word])\n",
        "    \n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "        \n",
        "    return feature_vector\n",
        "   \n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\n",
        "                                             num_features=feature_size)\n",
        "X_test_wordvec = pd.DataFrame(w2v_feature_array)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pSjiu4L6qkF",
        "outputId": "a992b60b-e34d-48df-a846-23a58fd4be63"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def generate_rf(X_train, y_train, X_test, y_test):\n",
        "    rf = RandomForestClassifier(n_estimators=5, min_samples_leaf=3)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print (\"rf score \", rf.score(X_test, y_test))\n",
        "    return rf\n",
        "\n",
        "def combine_rfs(rf_a, rf_b):\n",
        "    rf_a.estimators_ += rf_b.estimators_\n",
        "    rf_a.n_estimators = len(rf_a.estimators_)\n",
        "    return rf_a\n",
        "\n",
        "\n",
        "# in the line below, we create 10 random forest classifier models\n",
        "rf_wvec = [generate_rf(X_train_wordvec, y, X_test_wordvec, y_test)]\n",
        "# in this step below, we combine the list of random forest models into one giant model\n",
        "rf_wvec_combined = reduce(combine_rfs, rf_wvec)\n",
        "# the combined model scores better than *most* of the component models\n",
        "print (\"rf combined score\", rf_wvec_combined.score(X_test_wordvec, y_test))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rf score  0.16903633491311215\n",
            "rf combined score 0.16903633491311215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIAb4cCI7ONh",
        "outputId": "f4bb893f-113e-48c3-d2e5-add2df9ec408"
      },
      "source": [
        "# Print the accuracy score\n",
        "best_accuracy = cross_val_score(rf_wvec_combined, X_test_wordvec, y_test, cv=10, scoring='accuracy').max()\n",
        "print(\"Accuracy:\",best_accuracy)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.2868421052631579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zObk-nGS8tBf"
      },
      "source": [
        "def performance(ypred, yactl):\n",
        "    print(f'F1-score  : {f1_score(yactl, ypred , average = \"macro\")}')\n",
        "    print(f'Accuracy  : {accuracy_score(yactl, ypred)}')\n",
        "    print(f'Precision : {precision_score(yactl, ypred, average = \"macro\")}')\n",
        "    print(f'Recall    : {recall_score(yactl, ypred, average = \"macro\")}')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7d8hcIa8s9W",
        "outputId": "7ad1c5e6-6da8-4fda-cd75-d418779682df"
      },
      "source": [
        "rfc = RandomForestClassifier(n_jobs=-1)\n",
        "n_estimators = [150,200,300]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [10,20,40]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [150, 200, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 40, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J20gDyhh8s57",
        "outputId": "31d88aca-de19-4045-cf6e-2bde0bfb9049"
      },
      "source": [
        "rf_random = RandomizedSearchCV(estimator=rfc, param_distributions=random_grid, cv=10, verbose=2, random_state=42, n_jobs=-1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(tfidf_train, y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 11.8min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 52.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100, n_job...\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 40, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [150, 200, 300]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjlVJ-pU8s1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9d888c-8cb6-4808-aea0-476f06250349"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 40,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 4,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYouXk128syW"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=200,\n",
        "                             min_samples_split= 2,\n",
        "                             min_samples_leaf= 4,\n",
        "                             max_features= 'sqrt',\n",
        "                             max_depth= 40,\n",
        "                             bootstrap= True)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIKns6Gd8suM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e09836-d09e-4732-ae9f-5e8c5dc2cec9"
      },
      "source": [
        "rfc.fit(tfidf_train, y)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=40, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=4, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mirfqx48sr3"
      },
      "source": [
        "pred = rfc.predict(tfidf_test)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YR6iexN9rY2"
      },
      "source": [
        "pred_prob = rfc.predict_proba(tfidf_test)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpnpRaF59rVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad829e5e-19f6-4807-e7a0-cf726ee06cdb"
      },
      "source": [
        "performance(pred, y_test)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score  : 0.37443212086706157\n",
            "Accuracy  : 0.37651395471300686\n",
            "Precision : 0.4096311070020642\n",
            "Recall    : 0.3721776514954227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_onA0e6MSer",
        "outputId": "2ab7baee-5a36-44fa-832b-ad2b23f915c0"
      },
      "source": [
        "# Print the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "print(\"Confusion Matrix\\n\")\n",
        "print(cm)\n",
        "# Print the Classification Report\n",
        "cr = classification_report(y_test, pred)\n",
        "print(\"\\n\\nClassification Report\\n\")\n",
        "print(cr)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[157  18 188  85 144]\n",
            " [ 25 178  75  72 249]\n",
            " [110  37 345 218 331]\n",
            " [ 10  10 137 313 149]\n",
            " [ 35  98 190 187 437]]\n",
            "\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.27      0.34       592\n",
            "           1       0.52      0.30      0.38       599\n",
            "           2       0.37      0.33      0.35      1041\n",
            "           3       0.36      0.51      0.42       619\n",
            "           4       0.33      0.46      0.39       947\n",
            "\n",
            "    accuracy                           0.38      3798\n",
            "   macro avg       0.41      0.37      0.37      3798\n",
            "weighted avg       0.40      0.38      0.37      3798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MW04bu3MTlv"
      },
      "source": [
        "def confusion_metrics (conf_matrix):\n",
        "# save confusion matrix and slice into four pieces\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    print('True Positives:', TP)\n",
        "    print('True Negatives:', TN)\n",
        "    print('False Positives:', FP)\n",
        "    print('False Negatives:', FN)\n",
        "    \n",
        "    # calculate the sensitivity\n",
        "    conf_sensitivity = (TP / float(TP + FN))\n",
        "    # calculate the specificity\n",
        "    conf_specificity = (TN / float(TN + FP))\n",
        "\n",
        "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
        "    print(f'Specificity: {round(conf_specificity,2)}')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwiXXqy6NFHW",
        "outputId": "7a870dfe-6bf4-43be-b578-8512ade52c11"
      },
      "source": [
        "confusion_metrics(cm)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 178\n",
            "True Negatives: 157\n",
            "False Positives: 18\n",
            "False Negatives: 25\n",
            "Sensitivity: 0.88\n",
            "Specificity: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RvNumv9AWyA",
        "outputId": "f7819e0b-a9d6-4df5-8365-cf0d9188e884"
      },
      "source": [
        "pip install xgboost"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfMiyNhdBIm2"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OvBxmkhBIfV"
      },
      "source": [
        "silent = False,\n",
        "max_depth= 6, 10, 15, 20,\n",
        "learning_rate = 0.001, 0.01, 0.1, 0.2, 0,3,\n",
        "subsample= 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
        "colsample_bytree= 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
        "colsample_bylevel= 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
        "min_child_weight= 0.5, 1.0, 3.0, 5.0, 7.0, 10.0,\n",
        "gamma = 0, 0.25, 0.5, 1.0,\n",
        "reg_lambda= 0.1, 1.0, 5.0, 10.0, 50.0, 100.0,\n",
        "n_estimators = [100]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f4WIBQ_BHtP"
      },
      "source": [
        "xg = XGBClassifier()\n",
        "param_grid = dict(\n",
        "        max_depth = max_depth,\n",
        "        learning_rate = learning_rate,\n",
        "        subsample = subsample,\n",
        "        colsample_bytree = colsample_bytree,\n",
        "        colsample_bylevel = colsample_bylevel,\n",
        "        min_child_weight = min_child_weight,\n",
        "        gamma = gamma,\n",
        "        reg_lambda = reg_lambda,\n",
        "         n_estimators = n_estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKX1W2DVCBWQ"
      },
      "source": [
        "xg_random = RandomizedSearchCV(estimator=xg, param_distributions=param_grid, cv=kfold, verbose=2, random_state=42, n_jobs=-1)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPD1oW-_CWiB",
        "outputId": "46bdb3e8-8c2e-4b3a-8ab7-c84b7e4a7442"
      },
      "source": [
        "xg_random.fit(tfidf_train, y)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 26.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=7, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='bina...\n",
              "                                                             0.8, 0.9, 1.0),\n",
              "                                        'gamma': (0, 0.25, 0.5, 1.0),\n",
              "                                        'learning_rate': (0.001, 0.01, 0.1, 0.2,\n",
              "                                                          0, 3),\n",
              "                                        'max_depth': (6, 10, 15, 20),\n",
              "                                        'min_child_weight': (0.5, 1.0, 3.0, 5.0,\n",
              "                                                             7.0, 10.0),\n",
              "                                        'n_estimators': [100],\n",
              "                                        'reg_lambda': (0.1, 1.0, 5.0, 10.0,\n",
              "                                                       50.0, 100.0),\n",
              "                                        'subsample': (0.5, 0.6, 0.7, 0.8, 0.9,\n",
              "                                                      1.0)},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaUMwvHFCnmL",
        "outputId": "28239cb8-3397-45bd-d1c3-1f45261dff4e"
      },
      "source": [
        "xg_random.best_params_"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bylevel': 0.4,\n",
              " 'colsample_bytree': 1.0,\n",
              " 'gamma': 0.5,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 20,\n",
              " 'min_child_weight': 7.0,\n",
              " 'n_estimators': 100,\n",
              " 'reg_lambda': 100.0,\n",
              " 'subsample': 0.8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcxVNWJtCqFy"
      },
      "source": [
        "xg = XGBClassifier()\n",
        "param_grid = dict(\n",
        "        max_depth = 20,\n",
        "        learning_rate = 0.1,\n",
        "        subsample = 0.8,\n",
        "        colsample_bytree = 1.0,\n",
        "        colsample_bylevel =0.4,\n",
        "        min_child_weight = 7.0,\n",
        "        gamma = 0.5,\n",
        "        reg_lambda = 100.0,\n",
        "         n_estimators = 100)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy02KZnWCvhY",
        "outputId": "634d452a-fb8d-4a18-8655-ebdfccd68f3f"
      },
      "source": [
        "xg.fit(tfidf_train, y)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waj5-ZIwDJ-E",
        "outputId": "697690ca-c676-4b54-ff0f-9093c8c2d116"
      },
      "source": [
        "print(xg)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4aJlKjuDOOL"
      },
      "source": [
        "ypred = xg.predict(tfidf_test)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWoFJYsBDRci"
      },
      "source": [
        "predictions = [round(value) for value in ypred]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEWcDH_ADUdq",
        "outputId": "c2e7ecaf-393f-4c6b-ba74-3e042ac5e4eb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 34.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZvqnOZRhIqC",
        "outputId": "3ed1592b-4f2f-4656-dfee-0120f9ec059f"
      },
      "source": [
        "cm = confusion_matrix(y_test, ypred)\n",
        "print(\"Confusion Matrix\\n\")\n",
        "print(cm)\n",
        "# Print the Classification Report\n",
        "cr = classification_report(y_test, pred)\n",
        "print(\"\\n\\nClassification Report\\n\")\n",
        "print(cr)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[156  12 131  59 234]\n",
            " [ 21 138  58  47 335]\n",
            " [122  29 230 149 511]\n",
            " [  8   7  71 196 337]\n",
            " [ 35  73 116 114 609]]\n",
            "\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.27      0.34       592\n",
            "           1       0.52      0.30      0.38       599\n",
            "           2       0.37      0.33      0.35      1041\n",
            "           3       0.36      0.51      0.42       619\n",
            "           4       0.33      0.46      0.39       947\n",
            "\n",
            "    accuracy                           0.38      3798\n",
            "   macro avg       0.41      0.37      0.37      3798\n",
            "weighted avg       0.40      0.38      0.37      3798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKNyT-tErU7i"
      },
      "source": [
        "def confusion_metrics (conf_matrix):\n",
        "# save confusion matrix and slice into four pieces\n",
        "    TP = conf_matrix[1][1]\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    print('True Positives:', TP)\n",
        "    print('True Negatives:', TN)\n",
        "    print('False Positives:', FP)\n",
        "    print('False Negatives:', FN)\n",
        "    \n",
        "    # calculate the sensitivity\n",
        "    conf_sensitivity = (TP / float(TP + FN))\n",
        "    # calculate the specificity\n",
        "    conf_specificity = (TN / float(TN + FP))\n",
        "\n",
        "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
        "    print(f'Specificity: {round(conf_specificity,2)}')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT_oekXdrgE2",
        "outputId": "b918fb88-2cbd-4a57-da59-1a35b3153cb2"
      },
      "source": [
        "confusion_metrics(cm)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 138\n",
            "True Negatives: 156\n",
            "False Positives: 12\n",
            "False Negatives: 21\n",
            "Sensitivity: 0.87\n",
            "Specificity: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrbnUv08tdfI"
      },
      "source": [
        "pred_prob = rfc.predict_proba(tfidf_test)\n",
        "pred_prob2 = xg.predict_proba(tfidf_test)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trohPqHBtdaN"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
        "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "AQs2RQE6wJLm",
        "outputId": "7af89c12-1753-4ef7-99c9-14f9bced263b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Random Forest')\n",
        "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='XG Boost')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('False Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('True Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RU1drH8e+ZnkkPJAFJQu+9SBXp0kREEZGmCCKXJiBKFVGpikhVkWJBvSCgV2xYAAWk96L0lgCBBNIzfc77R3A0LyVIyqQ8n7Vca+a0ec52yG9O21tRVVVFCCGEEAWGxtsFCCGEEOLfkfAWQgghChgJbyGEEKKAkfAWQgghChgJbyGEEKKAkfAWQgghChidtwsQQvw7lStXJioqCq1WC4DL5eL+++9n0qRJmM1mAK5evcqcOXPYu3cvWq0Wo9FIz549eeqppzzbsdvtLFq0iB9//JG/nhjt0KEDQ4cOxWAw5P2OCSHumiLPeQtRsFSuXJnffvuNEiVKABkhPGrUKCpUqMCoUaNIT0+nW7dudOrUiaFDh6LT6YiJiWH48OG0adOGYcOGATBy5EgsFgtvvfUWAQEBJCYmMnbsWPz8/Hj77be9uYtCiCzIaXMhCjiDwUDz5s35888/Afjqq68ICQnhhRdeQKfLOLkWERHBzJkzWbp0KSkpKZw8eZLffvuNWbNmERAQAEBQUBDTp0+ne/fut/ycDz74gDZt2tC+fXtmzJiBqqp8+eWXPPPMM55l/vl+3LhxzJgxgy5durBw4UIaNmyI0+n0LDtkyBD++9//YrfbmTp1Ku3bt6d169a8//77udBKQhQuEt5CFHBJSUl8++231K1bF4Bdu3bRqlWrm5arXLkyISEhHDp0iF27dlGnTh2CgoIyLVOsWDGaNGly07p79uxhzZo1fP3113zzzTfs3buX9evXZ1nb9u3bWbNmDcOGDaN48eLs2bMHAIvFwo4dO2jfvj1Llizh1KlTfPPNN3z77bf8+OOPbNq06V6aQogiQ655C1EA9e3bF61Wi8PhICkpiWeeeYbnnnsOyAjz4ODgW65XvHhxkpKSSEpKolixYnf9eZs3b6ZFixb4+fkBsGLFCgwGA19//fUd12vSpAlGoxGA9u3bs3HjRho3bsyWLVuoVasWISEhbNq0iUGDBmEwGDAYDHTt2pWffvrplj9AhBAZ5MhbiAJoxYoVrF+/ntWrV6PRaOjUqZPnFHlwcDBXr1695Xrx8fGEhIQQHBzMlStX7vrzEhISPKfXAXx8fDw3zN1JYGCg5/Vf4Q3wyy+/0KlTJwBSUlKYMWMGHTp0oEOHDnzyySdYLJa7rk2IokjCW4gCLCQkhL59+/LWW295pj344INs2LDhpmVPnDhBUlIStWrVomHDhhw8ePCmAE9OTmbevHn8//tYg4ODSUhI8LxPSEggISEBjUaDy+XKtP7tVKlSBa1Wy7Fjx9i6dSvt2rUDICwsjMmTJ7N+/XrWr1/Pxo0bmTt37r9rCCGKGAlvIQq4/v37s3//fnbt2gXAI488gtPpZObMmTgcDgAuXbrEuHHjGDJkCGazmfLly9OpUydGjx5NfHw8AImJiYwePZqEhAQURcn0Ga1bt2bjxo0kJSXhdDoZOnQoW7duJSwsjLNnz2Kz2bBYLFleB2/fvj0LFiygatWqnlP7bdq0YfXq1bhcLlRV5d1332Xz5s053UxCFCpyzVuIAs7Pz49BgwYxa9Ys1qxZg1ar5cMPP2T27Nl07NgRnU6H0WikT58+PPHEE5713njjDd577z169+6Noijo9XoeeeQRBgwYcNNn1KlThwEDBvDoo4967m5/+OGHcbvd1K5dm/bt2xMREUGbNm34/fffb1tr+/bteeyxx5g6dapnWq9evYiJiaFz586oqkqNGjV4+umnc7aRhChk5DlvIYQQooCR0+ZCCCFEASPhLYQQQhQwEt5CCCFEASPhLYQQQhQwEt5CCCFEAVNgHhWLi0vJ0e0FB5tJSEjP0W0WRdKO2SdtmH3ShtknbZh9udGGoaH+t5xeZI+8dbqsu3YUWZN2zD5pw+yTNsw+acPsy8s2LLLhLYQQQhRUEt5CCCFEASPhLYQQQhQwEt5CCCFEASPhLYQQQhQwEt5CCCFEASPhLYQQQhQwBaaTlvzo8uVL9OvXk8qVqwDgcDgoV64CY8aMQ6u99+f9Bgzoy9SpsyhZ8r5s19i9exfCwsLRaP7+nbZw4QfZ3u4/xcbGcv16PNWq1cjR7QohhLi1XA3vEydOMGTIEJ555hn69OmTad62bduYM2cOWq2WBx98kKFDh+ZmKbkmKqp0pjCcNm0KP/+8ng4dOnuxqsxmz56P2WzOte3v27cbiyVdwlsIIfJIroV3eno6b7zxBk2aNLnl/KlTp7Js2TLCw8Pp06cP7du3p0KFCrlVTp6pVq0GMTHRACxYMIc//jiK3W7n0Ucfp0uXR5k2bQrFi4dy/PifXLkSy+TJU6lcuQpz577FkSOHiYoqjdPpAODq1SvMmPE6DocDjUbDuHGvoCgKb7wxmVKlIjh8+BDduj3O6dOn+OOPI3Tr9gSPP97jrurcsOFnVq36DK1WS+XKVRk5cgzLli3m0qWLXL58iQULFrN06fscOnQAt9vFY4/1oF27DuzatYMlS97FaDQRHBzC9OlvsHz5B+h0OsLDS/DAAy1yrW2FEEJkyLXwNhgMLFmyhCVLltw0Lzo6msDAQEqWLAlAixYt2L59e7bDO2TLrY/80suMwBo5CAD/I8+hT9gOWoUQl+pZxhHYgJRaHwFgivkI89nZXG9+5F99vtPpZMuW33j00cex2WyUKHEfw4ePxmaz0qPHo3Tp8igAdrudOXMW8r//rWH9+u8wGAwcPnyIJUs+Ji7uKj17dgNg6dL3efjhrrRp8xCbNv3C8uUfMGDA85w8eYIZM2aTnJxM3749WL16HXa7nYkTX76r8E5PT+eDDxbx4YefYzabefnlUezbt+fGPjh4992lHDy4nytXYlm0aAl2u51nn+3Dgw+2ZO3aVQwbNoratevy228bcblcdOz4MEFBQRLcQohCyeV23TRNURQ0igaHy8F7BxeSHOfP0IfaE6xE5klNuRbeOp0One7Wm4+LiyMkJMTzPiQkhOjo6DtuLzjYnHW/sVrllpP9/Uz4/9W5u1HvWU77j+W1Rj2mv5ZJMoFWuW2H8H+x2XyJjj7P6NFDADh+/DgDBw7k8ce7AOByWRk+/Dn0ej1JSYmEhvpjMul58MGmhIb6U6FCGc6cOcH165epX78u4eGBhIcHEhkZSUiIL6dOHWfixHEUL+5Pu3YtWbFiOSEhvpQuHUWFCpGkpaVRrFgxqlUrT1paGhZL2k01a7Uaxo8f5bkGHxwczPPPP0+5cmUpXTocgObNm3Lp0jl8fY3cf399QkP9OXPmGMeOHfXsm0YDqmrlkUce5p13ZtGlSxc6d+5MaGgovr5G/PxMWbaXuD1pu+yTNsw+acMMcWlxBGjAqNrpuPYZ1p/55aZl+kdWY3nth0hz65k61wa/jEF57TBzJ+RNGxaYG9buaqSWpodvP++vUckqvgsVM76kN41U9tf7wJ7QtOff72/j+vU0IiNLM2fOuwBMmvQyISEliItLYf/+vWzZ8jvz5r2HTqejXbvmxMWlYLU6SE21ExeXQlKSBYvFTlKSBZvN6anH4XBy/XoaLpdKfHwKqmokPj4RtzvjM1VVIS4uhfT0dBRF43ntcrlv2ieXy82MGe9kuuZ94sSxTJ+XmJiK0WgkLc2GXu9DXFwKdrubjh270Ldv/0zba9asDdWq1WXz5l957rlBLFq08MZ61hwf+a2ouOV3Ufwr0obZVxTa8HLqJeIsV9Fp9FQrVh2AWbumcTbpNKigST/FV5cO4kJl/X3Q3heaa5qyHmhRvBIa6wUUlxWAqpY/OPWbjf5LPoFjTfEPslK7dMUcb8Pb/aDySniHhYURHx/veX/lyhXCwsK8UUqOGjLkBV58cTiNGjUhKSmRsLBwdDodW7f+hsvlxuFw3HK9qKjSfPHF56iqypUrsVy+fAmAqlWrsW/fHtq168CBA3upUqVqjtQZGVmamJgLpKenYTb7sn//Pp5+egB79uz0LFOtWg0WLZpH795P43A4ePfdeYwa9TIffbSUxx7rQdeuj5GQcJ3Tp0+j0WhwuW4+rSSEEN604/J23t49E5fqIt4Sx7HrfwIQaTByqk4jALaeOsPOxJhbrq9qTDxV/nF6tvwCf0MAGmsMGvs13G5Y+mlJar1ZBotVS5eOKcycrVCtWkie/QDySnhHRESQmppKTEwMJUqUYNOmTcyePdsbpeSo++4rRcuWbfj442X07v00n332McOGDaJ58xY0bfoAs2fPuOV6FSpUpFy58jz/fH8iI6OoWLESAAMHDmbGjDf45pv/odPpGT/+FZxOZ7br9PHxYejQjB8aiqKhVq061K5dJ1N416xZm7p16/P88/0BlW7dngAgPLwEI0cOwd8/AH9/f4YNG4zTqTB16hSCgoJ56KGO2a5PCCHuhS5xF7q04573SZf2cz31HIcTz3qmhWthoJ8NQ8JmAFZXfoTEKhtAdWM+MwtVH4wuog9+xhDiDcXw+8f23aYI3KYIrl+Htxb5YvJRmDvPwqOPgqKo5CVFVdVc+cQjR44wa9YsLl68eONO5HBat25NREQE7dq1Y/fu3Z7AfuihhxgwYMAdt5cbpyIK+ymivCDtmH3ShtknbZh9+aoNVReoblC0oNzoo8Kd+cyl4kjAFLua08YqrL54AP21DRgStmJT4bXr0NEM35cCa3BLkur/D4Dg3+ujt13CHvIgaRVfx+Vb+cbGsu6vzO2G6GiF0qUzInPHDi1ly7oJD/87QnOjDW932jzXwjunSXjnT9KO2SdtmH3Shtnn1TZ0paFxJKBLOYr53Bz0idsBSKqzii3OYP53ag3miytQ3BbPKnUM0D8Qvg0bTZff59xys0mPvo/bWAJHsdbZKu/8eYVRo0ycOKFhy5Y0goNvvVxehneBuWFNCCFEIeK2o7htqDp/jLFfEfDHkEyzVTS49cX49NByVh3//KbVHw8J5cmo7lQO78HK4AcyzdMqWu4v0QibPnudU7nd8PHHel57zUh6ukKHDg6cTgXw/jGvhLcQQohcZT71OvrEnfwz9AwJW0mq9Qn20Idxm8tiLfkkLtXN1jQ78+OTSXDaWRtQj77VVAxaA/1rPJdpmwGGANICShMEtA6qluM1R0crjBxpYssWHYGBKosWWeje3Yly6yeS85yEtxBCiHumS9iOz8Xl6JL3wz+uwtrCu5JeYXLGMmknMCRsuWldn4sfYw/rwknNfcy5qmPlsc8yzVdVlYYlG9GwZKPc3YlbGDHCxO+/63joISezZ1spUcL7R9v/JOEthBDijhRHEsbYNWgc1/E9/QZuXQDXm/+BqgvAdHklpsurAHAbMh75tbtVHI5Uz/pLNE0ZfnId/oYAFP4+dN3UeB6RipYDV/d5glun0dG90pP0q9YfvVafh3sJ6enwV5cY06bZOHTIwZNP5p+j7X+S8BZCCHFrqgvfk5MxxXyExvX3jVgaZzLqjRGl48Me56irON9eu4xVY+ZEwgm2xPxKo8SDfFMVrqRf4buYjKPuFHsy1YvV9GxHp2REUL3wBixut5w2Ue0IMAbm4Q5mUFX47DM9U6caWLPGQo0abqpVy/gvv5Lwzobdu3fy8cfLPKOKxcVdZcSIwSxd+gm+vn78+OP3rFmzEr3egNVqpX37jjz5ZO+bttOiRSNq1qwNgM1mpU+f/rRo0Srb9aWlpXL06BEaNmyc7W0JIYoItw2t5QIu34qgaNGlHEbVmkktOxpnQF1+jT3I1uTrjNVlPAH97fXLDNnyVqZNlA+qQN2w+gCEm8PpVuFxaofWYVCt/+BvCLjpI6MCShMVUDr39+0WLl3KuJN80yYd/v4q0dEaatTIv6H9FwnvbLj//kasX/8dP/zwLR07PszChe8waNAQfH39OHToAF99tYa5c9/F19eP9PQ0XnhhCGXLlr8pTP38/Dw/AGJjYxk1akiOhPfx48fYtWuHhLcQ4o4URwJc/I3AgzMxJP6OI6AuifdvAI2OlOrv4TYU57o9lQlbXuLLk2sAqFeyGe3KdCDKvww9Kj9FndC6NC3VHL1GT/mgCmj+8ex0t4rdvbVrt6WqsHKljkmTTKSkKLRq5WTOHCulSuWva9u3I+GdTcOHj2bYsOduBHQ6rVq1BWDt2lUMGDAIX9+MX6dmsy/vvbfstoO1/CUh4RqhoRnXjVJTU5k2bQqpqSk4nU5GjnyJypWr3HI4zxMnjvH227PQ6/UYDAZee20Gc+a8SXp6GpGRUXTt+ljuNoQQokAyn56J+dw74LZguDFNl3rM03HJ4dQEZu16kQ0XfsbhdqDX6Bla5wUejMw4wPDWDWXZtXixnsmTTfj5qcyZY6V3b0e+vLZ9O4UqvOuvuPWQoEPqjGBAzYwhQYf88hw7L29Ho1Fwu//+hVU/vAEfPPQRACv++Ii5e2ezt2/WQ4IGBQXRs2dvXn11PJ99tsYz/fz585Qrl3mI09sFd2pqKsOGDcLlchITE8Nrr00HYPXq/1K9eg369HmGY8f+YMGCObz55txbDue5efMmunXrTocOndm7dzfXr1+jV6++nDlzWoJbCOFhjF2LNu0k1ohncBvC0Cf+jqrzQynzHElqGCsS7cQ4XTxrSyTQGMS+q3tYf+57qherSceynWkd1ZYGJRp6ezfuyV83wysK9Ozp4OBBLRMn2oiIKBhH2/9UqMLbW06dOkmJEiU5duxP7ruvFAAajeIZrOPIkUO8//5C7HY7lSpVYcyYcZnW/+dp82vX4nnhhSG8++4Sjh37g379MrqNrVKlGjEx0URHXyAiIsozSljduvU5ceIYDzzQgtmzZxIdfYE2bdpRunQZjh69wyhrQogiRXEkoks9SsDhjJECjZdXklLrY5Lqf8OHR5Zy/OIRlh+Y71l+1q5pHOj3Jw+UepDfntxB1WI5/yx1XoqNVRgzxsTjjzvo1s1JUBC8957V22Xds0IV3ndzpPxu2yXAnbux61vtGfpWe+auPvOPP45w9uwZFixYzMiRQ2jcuClms5myZcvx559/EBYWTo0atVi48AP27dvDl19+ccftFStWnLJly3Hq1EkUReGfvde63W4UhUzTnE4HRqORBg0asnTpJ2zbtoWpU6cwbNjIu6pfCFH4adNOErupPkk37sPaaYXj2vq87l8LVVXZdnErX5/+0rP8yHpj6F7pSe7zK+WlinOOqsLq1TomTjSRlKTg46PSrVv2B3jytkIV3nnN6XTy9tuzmDhxCsWLh9Kp0yMsW7aY4cNH8cQTTzFjxuvUqlWb4OAQ3G43+/btwWAw3nGbdrudM2dOUapUBFWqVGP//j3UqFGTI0cOU7Zs+dsO57l27SqaNHmAhx7qiKqqnDhxjMDAIBmqU4giSGOLxRSzDGdAffaq4Ty7/inOp2ZeJiD5J0Y3TSTIFEy/6v1pW6kVdQMbUyG4YqabzQqyK1cUXnrJyPr1esxmlTfftPL007cemrmgkfDOhpUrP6VOnXqUK1cegB49nmLAgD6cPn2KKlWqMXToSF5+eSQ6nR673U716jUYOfKlm7bz1zVvyHhUrEePXoSHl6BHj6eYPv01RowYjNvtZvTosbcdztNiSeeVV8bh5+eHXq9nwoRXSUxM4P33FxAaGkavXn3ztG2EEHnvo0PvMn/PTIyuRKJ0sDEC0su+y8X0q5QPLEeHsl3QKlqCTME8VaUPQaaMETaaR7QgNPThQjW4y4kTGrp0MZOQoPDAA07eecfqGRGsMJBRxUS2SDtmn7Rh9hWpNlTdOBxJ2Fx2jFoDx64f56n1fUm1p5DuTPcs1tQE33dZhT20411ttrC1ocsFvXr58NBDTvr3d6DJg5MJMqqYEEKITDSW8/hceJ8vjiyi/5WMae+HQS9/WNzyUybvegudI57ijot81XgwlgqvYNfd+g9/YaSq8L//6YiO1jBihB2tFlautBSox7/+DQlvIYTIZzTpZ9DaYvE5NweXuTxplWdxMvkSk3d9ws83DuwqmsyUDKmCITiUB0o9yIYej6DY4/A9NY3UyjNA0Xp3J/JQXJzC2LFGvv1Wj5+fSp8+dkJCKLTBDRLeQgiRbyiORIyxq/E/9mKm6X+WHEL7b3qQbM9I7r5Vn+btVgsASP7HcqohlNRqc/Oq3Hzh6691jBtn5No1DY0aOZk3z0pIiLeryn0S3kIIkU/4XHiXpBMzeT0BliZDoCGAGqF1+DCgNPv7HWXh/rnUDWtAh7KdvF2q17lcMHiwia+/1uPjo/LGG1aeey5vrm3nBxLeQgjhBYrtCiknZnLx7HKaBEcwxXcgc/bMJ/0fjyAnWpOppssYyMPfEMD4RpO9VG3+o9VCUJDK/fe7mD/fQvnyBeLe6xwj4S2EEHlIm3IIn+ilGGI+IuI0POUHEYartKnajvPJZ7mQfJ42pdtRKbgKLSJaodUUnWvXWbl2TeHzz/UMG2ZHUeD1120YDBlBXtRIeAshRG5QXeiS92G6+BkaazTp5V7G4VeTSdunEXP5B07YwabCRykwpcdpqhsDeLvl/Ky3W0R9952Ol14yEh+voVw5N507O/Hx8XZV3iPhLYQQ2aRL3o/GFut5ptrvj+H4XPw40zKG65v4OWoG7536AQCNoqFX5ScZ2+hVzMabx7gWGa5fhwkTTHz5pR6jUeXVV6106FDwuzfNLglvIYT4N1wWTLFrwJWGxpWKPn4DhsTfUVGIb5cEgDb9DBddeh6+6CAeX9D6sOaRbyiu96dnlQMk25J5r91SfHRF+NDxLvz8s5ZRo0xcvaqhfn0X8+dbqVjR7e2y8gUJbyGEyIrqwnTxY6z39UOfvA/TxU/QJ+30zHYbwnD61/K83172Tfof781Z2xkgjSj/4qA1EekfxX9qDycqoLQE9124dElDYqLCK6/Y+M9/7NxmVOUiSZpCCCHuQHEkUPzX0gA4/arjCG6GI6ghthLdcJnK4Ayoi9tU0rP88iNLGLc54zntXlX6MuPB2ZmCuqAPrZnbNm7U0qiRC19f6NfPQYsWTsqUKVp3kt8NCW8hhPh/tKl/4nt6GrhtGON/9ExXXGkk2RLpc/IkKiduTP3QM/+NB2bSs3Jvxm1+kWkPzOK5Wv/J48oLrsREmDTJxBdf6Hn+eTtvvGFDUZDgvg0JbyFEkaRNOYQu7eRN053+tXEbimML64r/0Yzw3WeFz0IGM65Ya1zWa2y48DMu9ebhdl++fwLlAstz9rnL+Op9c30fCotfftEyerSJ2FgNtWu76NWrcAzbmZskvIUQRYI25TCGhK04/WriCHkA0+VVmM8vuGk5p29l0spPwBbWhTUpLqbseJ3o1Bga2PfxsuomxFSMKU2n8ljFHvjoM1+39tFmvJfgvjtJSTB5son//lePXq8yfryNYcPs6PXeriz/k/AWQhRebie61MOYz87BePVrANKj/oMj5AFsYY/g8il70yqqxoS9WDsupscz4JdBnuktI1ujUTL63ny+9tC8qb+QO3FCw8qVOmrWzLiTvHp1uZP8bkl4CyEKD9WN4khANRRDscdT/LdynlmOgPpYIgfh9K8JgDOoEc6gRp75v5z/kVOJJxlceyAASw7PBEBB4eLga+g08ucyJ6SkQFqaQokSKvff72bVKgvNmrnkaPtfkm+jEKJQ0CXuJHh3O9Ijnyet0lQUZ4pnXlKdVdiLd7hpjEiX28XyIx+w6cIGfrnwEwoKg2sPA8BP78dDpTuwrMMKCe4csmlTxrXt0qXdfPmlBY0GWra8+d4BkTX5RgohCizFmYLp4sewbTHBaecBMEcvJq3iG7hNEVxrdhC3TxTx1gS2nFqLv8GftqXbA7D+7PdM3Poy0SkXPNurFFzZ8/r52kPw0/ujFOZBofNISgpMmWJkxQoDOp3KU0+5cLspMiOA5QYJbyFEgaFJP0vI73VJq/AqlrKjUOxx+J2Y4JmvohDf+gpoTQBcxsx/973D9J2vA1A2sJwnvBNtCUSnXOCJSj15pclrBBgCMelMnm35G6TL0pzw228ZvaTFxGioWtXFwoVWataUa9vZJeEthMjXtCmHMF3+Ao01BtOVLwHwiVmOpewoVH0xUqrOxT8ohDifh0Br9qz3y/kf6fXdE5m2NeEfQ2reX6Ihe/ocJiqgdN7sSBGUmgrPPedDSgqMHm1j9Gg7BoO3qyocJLyFEPmaIeF3zOczj7aV0GQbAKo+EGvEs/iH+kNcxjVut+pGo2gINAbRqGQTkm3JjG/0Ci0iW2Xq6ax8UMW824kiJiUF/P3Bzw8WLLBQooRK7dpytJ2TJLyFEF6nOBLQJR/AeHUd2vQzcOORLEvkIGzh3dAl7sJSegiqxoTLr8ZNN5453U5GbRrGheTzbLn4G/+pPZzXmk3jm24/3urjRC5JTYU33jDy8886fv01jYAAaN9ebkjLDRLeQgivK7a5EorbdtN0W2hH3KEdSan14S3WgnRHOn2+78Gu2B3YXXbP9FBzWK7VKm5t2zYtI0aYuHBBQ+XKLuLiFAICpGvT3CLhLYTwuoRGW/A7NhpHSEucflWxF2uXMUO5+U+UxWlh5+XttIxsjVlvJtgUgklnwqwz83qzGXSr2B2j1pjHe1B0paXB1KlGli0zoNGojBhhY8wYOyZT1uuKeyfhLYTIE4o9DvO5eZmmmS59ii20M9bIQSQ1+D7LbVxOvUTtT6oQ6R/F6i7/o1xQBZY89BHhYYHExaVkub7Ief/5j4n16/VUrJjRS1r9+nJtOy9IeAshcp7Lgi7tOD7nF6BqfEitvhCNI+GmG88AfC6twFbyyTtu7kr6FeLSr9L6i2YARKdcwHDj6PqvLktF3lHVv287GDPGTvnyKmPH2uRoOw9JeAshco4zFf8/X8AUuzrT5NTqC3GZIklouOmmVdyGMNw+kXfc7IqjH/Lm7ume99t77SXC/87riNyxY4eWsWONLFlipVIlN7VqualV6+b7FUTukvAWQvwr2rRT6JJ2AWC88jVayxkskYOxRg5Aa43JFNyWyOewhXW7scH6sqQAACAASURBVKIPzsD6d/UZJxNOsGj/PEbUG0W5oArUC6/PczUH48ZNp7Jd5DEvL7BYYMYMI4sXZ3RCvnWrlkqV5BS5t0h4CyHumib9NME7mqG4LZmn268A4DYUJ63CZBwBDXCEtLjpka7b2XF5O7tjdwKw78oevj/zDSoqYeZwJjSeTOuodrSOapezOyPu2u7dGkaM8OH0aQ3lyrmZN89Ko0byCJg3SXgLIbKmqqA6UVQ3qA5SK7yGaigOgMtcHkdw04zFDMVJLzvmLjepkmxPItAYxJCfBxKTGu2ZVye0LiPqvUincg/n/L6If2XtWh1Dh5pQVXj+eTvjx9swm7NeT+QuCW8hxG1prJfxPTkRU+waUitNx1ryKa433Y3bXP5fb8vqtHIw7gC7YnewO3Yne2J3UiGoEuu6reezzqvZfvl3ovyjCDEVo25YfRkQJJ9o0cJF/fpuXnnFRuPGcrSdX+RqeE+fPp2DBw+iKAoTJkygVq1annmfffYZ69atQ6PRUKNGDSZOnJibpQgh7oHfny9gjF+f8frEBCxRQ1ENxbJcz+FycCrxJFWLVQPgld/Hs/zwBzjcDs8ypfwiaFiiMQBVi1XzLCu8y2qFt94y0KCBm44dnRQvrvLdd+neLkv8P7kW3rt27eL8+fOsWrWK06dPM2HCBFatWgVAamoqy5Yt46effkKn0/Hss89y4MAB6tSpk1vlCCFuQ3GmYIj7AVQHbkMYjuIZ15Z9T07xBHdSrU+wh3a8q2vYbtVN6y+aUTawHJ90WglAqE8o1YvV4P4SjWhYsjENwhtSyj8i93ZK3JP9+zUMH27ixAkt99/vokMH593etiDyWK6F9/bt22nbti0A5cuXJykpidTUVPz8/NDr9ej1etLT0zGbzVgsFgIDA3OrFCHEHYRsrozGlQqAPfgBkm6Et6rNGMTDZSyFPazrbYPb4rTQ9/ueHI47gKIoJNmScKkujiccw+6yY9AaGFFvNCPqjc6bHRL/ms0GEybArFlm3G6FAQPsTJpkk+DOx3ItvOPj46levbrnfUhICHFxcfj5+WE0Ghk6dCht27bFaDTSuXNnypYtm1ulCFGkKY4kfC4sRHGmoOpDSC/3MgCGK+vwOzHeE9xp5SfiCKjnWc8W9gi28Mdx+VbItL10RzpJtkTPe6POSIcyHdkcs4kqIVUJM4dj0BqZ03I+Bq2M/5jfXbqk0LOnD8eOQVSUyrx5Fpo1k2vb+V2e3bCmqn93UJ+amsrixYtZv349fn5+PP300xw7dowqVarcdv3gYDM6nTZHawoN9c/R7RVV0o7Zl2NtaI0DU2jG6z/ehPOrIGHf3/P9yuHb6I2M1/ZAUJwQ0gAiHsW3xv+77yS0Yaa3samxDFw3kO9Ofpdp+s6BOxnQ+GlGPjgMH70P3iLfw3sTHAwBATBkCMyapcHPT24lz468+h7mWniHhYURHx/veX/16lVCQzP+qJw+fZrIyEhCQkIAaNCgAUeOHLljeCck5OwNE6Gh/tIXcg6Qdsy+HGlD1Y3Pubn4xCwltdJM7OGPEBCzEeON4FY1RlIrv4UjqBGuvz7L0AIeOP73NrKoYdKWVzMF92MVn8h4YTGiGHxITXeSine+C/I9/HcOHdJw6JCWPn0ybiBcswYiIzPa0GLJYmVxW7nxPbzdj4FcC+9mzZqxYMECevbsydGjRwkLC8PPzw+AUqVKcfr0aaxWKyaTiSNHjtCiRYvcKkWIwsltw3TxE3xPT0XjSPBMNp97B3v4I6TUWEyq246q6O/qDvF/+uX8j1xNv8qf147SuXxXGpdswtRms1h2+AM29vidGsVr5vTeiDxgt8OcOQbmzTOg0UCbNk5KllSlT/ICKNfCu169elSvXp2ePXuiKAqvvvoqX375Jf7+/rRr144BAwbQr18/tFotdevWpUGDBrlVihCFi+oCVUWfsA3z2bc9we3WBWGNGEBa2RczFtOH8G9HU3a5XXx+bAUv/jrCMy3daaFxySZoNVqu/CdJnr8uoA4fzriT/I8/tEREuHnnHSslS8p42wWVov7zYnQ+lhunIuQ0W/ZJO2bfXbehy4rPhUX4nXoNa8mepNT4AI3lHPqkfdhCO4D23q5VOlwObC4rqY5UHlzZiMQbN6PpNXo+6fhfmke0zPc3nsn38PZUFWbPNvDOOwacToW+fe1MmWLD//+djZU2zL5CcdpcCJEzFGcyPhcW43v6jZvmuX3KYPMpc8/b3nF5O8+u783o+i/zTI2B/NT9N175fRwWp5XPO6/O96EtsqYoEB2tISxMZc4cC61by53khYGEtxD5nO/x8fhcWuF5n15mFGkVX7vn7TlcDrZd2soPZ79l+ZElGdt0pqPT6CgTWJYVnVZlu2bhXQ4HfPedjq5dMzpZmTrVCmTcVS4KBwlvIfIp48VPcfnXILXqXJyB94PbhjVy0F2P1HU7U7ZNZMnh9z3v7/MtxeDaw7Jbrsgn/vhDw4gRJg4d0gIWHn3UKaFdCEl4C5EPBe1qgz5pNwBxba5jjXgmW9vbf2UvlUKq4Kv35ZUmr7PmxCq6V3qSjuUe5oFSD+ZAxcLbnE5YsMDA7NkGHA6Fnj0dtGrl9HZZIpdIeAuRn6gqQTubo085BEBqhddAc+//THfH7uTtPbPYeOEXpjSdxpA6wzHpTBwfcD6nKhb5wLFjGUfbBw5oCQ93M2eOhXbt5Np2YSbhLUQ+4ntivCe4Uyq/iTVq8D1tZ/ul33l7z5tsjtkEQLP7mlMvXB7HLKw2b9Zy4ICWHj0cTJ1qJSjI2xWJ3CbhLYS3xW4gcP8UUmouxx7aEa3lPI7gZvcc3BO2vMTSw4sBaBHRihcbjKXxfU1zsmKRD5w6pRARkdHBysCBDqpXd0uf5EWIhLcQ3rZnKIbk42jTT+MIaYEj5Pa9DV63XuOb01/fcl7rqLZE+kfRKrINZ5POMLrBy9xfolFuVS28xOWCd9818OabBp57zs7kyXY0GiS4ixgJbyG8QJe4E8O1TSjOJEjO6F/cEVA30zIbL/zMvit7SbQl8J/awynlH0FsWiwv/Tbyltv8tNMqIv2jaFemA+3KdMj1fRB57+TJjGvbe/dqKV7cTYMGbm+XJLxEwluIPKKP/wWXbyXcplLoE3fhe2b6jRkBWMKfAK2Z49eP8e6B+Wy7tJXzyec866489jk7ex+glF8p3m+37Jbbr1m8dh7shfAGlwsWL9YzY4YRm03hscccTJ9u5cbYTqIIkvAWIg/4nJuL38nJAFxr/ge28EdxBtQCtPiXfYBLV5MIAGwuK/899ikBhkCal2pBhH8k3Ss9SZg5nGI+GYOLeEbzEkXGgQMapkwxUby4m/fes/Lww/IIWFEn4S1EblFVzGemY4j7CX3KfgCcvlVwmyLYd2UPOy8f5rM/PyY2/TJdyz/G2y3nU71YTTY8sYVqxWqg1eTs+PWiYHG7ISUFAgOhfn038+dbaNvWRfHiBWI4CpHLJLyFyEmudAIPPEVyjQ9Q3DZMFz9Fa7sIZAR3QtNd9F/fh+/OrMu0Wpg5HACtRkvNUDn9XdSdOaPwwgsmfHxg1SoLigI9e8rRtvibhLcQOSjwYC8M1zfhE7Oc9PLjSWjyO/qEHdjDOnmWKR9YAYDmpVrQvdKTPN/0WZIT7N4qWeQjbjcsXapn2jQjFotCly4OLBYw39uAcaIQk/AWIgcZrm0EwGWKBDLG1LaHdcKtuvnwyFJqFq9Nr6p96FH5KSqFVAbAqDMCEt5F3dmzCiNHmti+XUdIiJv586107SpH2+LWJLyFuEfatFO49YGohlB0SXsxn52NquhQVCe2Un08yy3aP5/Xtk8C4IlKPVnU9gNvlSzyKasVunQxc/Wqhs6dHcyaZSMsTK5ti9uT8BbiX1IcCfienopP9BKSayzFVrIHGvtVjHHfAWAt0R2AZFsSb+6ezgeH3vOs27BkY6/ULPInlwu0WjCZYMoUG1otPPqoM7sDx4kiQMJbiLukS9pNwME+aG2XAXAZSuDyrQSAvVhb4lteAEDVBQLw1am1rDz2OQC1Q+vyw+Mb0GVjkBFReLjd8NFHej75RM+336bj5wfdu8spcnH35C+JEHcp4EBvtPZYANz6YBKa7kbVZwQ1Gj2qJogT14/z1alF1A6ty9PVn6VySFUup16ka4XH0CgaL1Yv8osLFxRGjTKxZYuOoCCV48c11K8vPaWJf0fCW4isuNJQXBZSq85Fn7AZS+lhuE0RmRb59vQ6vjjxX9afzTh1btKaeLbmIKY0neqNikU+pKrwySd6pkwxkpam0L69k9mzrYSHy7Vt8e9JeAvxT6obfeL2G69VfM69g/Haz1giBpJadQ72sE5YnVYuJZ2mXGB5ABYfXMQrv48HoJRfBBWDKzG6wVhqSXel4h9eftnIxx8bCAxUWbjQwhNPyLVtce8kvIUANJZo3D6RoDoJ2tPxpvm6pD0AXLNco+qHZTHrfNnQYzPlgypSMbgyDUs0pmPZhxlad0Rely4KiCefdBAbq+Gtt6yUKCFH2yJ7JLxFkedzfiF+JyaQHjmYtErTSSv7cqb59rAuHLAp7Dj0PhO2ZsxLd6ah1xiAjKE4W0e1zfO6Rf4WE6MwYYKRKVNslCun0qCBmxUrLN4uSxQSEt6i6FLdmKI/wO/EBAAUtx00OtIrZDyT7Vbd2F12TDoTL61tw94ruz2rHn/2HMEmGdJJ3ExV4fPP9bzyipHUVIXKld1MnCid8IicJeEtiia3ndANxT1vXaYoUitnDNG5YP9cDscdYOvFzYysN4ZBtYfQtUI3SvlF0LXCY9QPbyDBLW7p0iWF0aNNbNyow99fZe5cC089JY+AiZwn4S2KDtWNLnk/qi4AVWPAWrIXpsufk15mNGnlx4PGyNaLm3lje8bQnaE+YUT4RwEwuPYwkPvPxB1s3qzl2Wd9SE5WaNnSyTvvWClVSq5ti9wh4S2KBtVNyO910FrOYQ9phSVqMClV3yal2jzQGAE4lXCSAev7AtAysjUrH/5Sns0Wd61yZTeBgSpTptjo3dshd5KLXCXhLYoE08VP0FrOAaBqfXH6VQOtb6Zl3to9nQRbAtMfeJOBtQZ7oUpRkKgqfPGFjrAwlVatXISHq+zYkYZe7+3KRFEg4S0KPcV2Ff8/R6CqEBvwAL8FP8O2A8tZsP8dFBSerz2U15tN551Wi+hUrgtdKzzm7ZJFPhcbqzBmjImfftJRsaKLLVvS0WiQ4BZ5RsJbFF6qisZ2GW3qUexBTdElbOO+fVuBrX8vgkqkf8bwnWa9WYJb3JGqwpo1OiZONJGYqNC8eca1bY1cXRF5TMJbFEpJl7/n/K6efGILIzWoGfObLUZnCqOz+zkA/PR+9Kven+rFamLWm71crSgIEhNhxAgT69frMZtVZs2y8vTTDglu4RUS3qJQ2XdlDy/99gKH4w/fmHIV4r8i0FSMWQ/O4cMOn3q1PlFwmc0QHa2hWTMnc+daKV1a7iQX3iPhLQoPVUXz5zjOXT+MnwI2FUY3eIk64Y1oHdXO29WJAujqVYU9e7R06uTEYIAvvrBQrJgqR9vC6yS8RYFncVp4/ffxHIg/xMZmQ7iuv47GfpXkOqtwBDfzdnmiAFJV+PprHePGZfSStnlzGuXKqYSGytG2yB8kvEWBV2N5aVKcVgC2qJE0bLbPyxWJgiwuTmHsWCPffqvHx0fl1VdtlCkjoS3ylyxP/iQlJTFr1izGjBkDwMaNG7l+/XquFyZEVpzHJlLqvUBPcH9wXxANStzv5apEQbZunY4HHzTz7bd6GjVysmlTGs89Jzelifwny6/kpEmTKFmyJDExMQDY7XbGjh2b64UJcSeKM5mLJxfgUDOOiJ4J1PNo13PSI5rIlu+/15GWpvDGG1b+9z8L5crJEbfIn7L8S3f9+nX69euH/kbvAx06dMBqteZ6YUL8fzaXjQ+PLKXisii2xh6gzH2deb1MLQ70OcSbva+BBLe4B3v3/v29mT7dysaNaTz/vAOt1otFCZGFu7rm7XA4UG501BsfH096enquFiUEgGKPw+fC+yhuKyP/3MSSi0c88wau78mfAy8hnZiKe3X9Oowfb+Krr/QsW2ahSxcnISEQEiJH2yL/yzK8e/fuTffu3YmLi2Pw4MEcPnyYiRMn5kVtoojTpp1Ca41m7fGVLLmSMa2mAV4vU41GVYZ7tzhRoH3/vY6XXjISF6ehfn0XVaq4vV2SEP9KluHdqVMn6tWrx/79+zEYDLz++usEBATkRW2iiNKm/kHCkbGMTTCxuPUCyvq3h+/60610axZ3/AI0Bm+XKAqohASYMMHE2rV6jEaVV16xMWSIXU6RiwIny/AeMGAAy5Yto2PHjp5pjz/+OGvXrs3VwkTRE2+Jp8valvhYL3DEnjGt66V9tC3dlRPPnifIFOzdAkWB98UXetau1VOvnov5861UqiRH3KJgum14r1u3jkWLFnHp0iVatmzpme5wOChevHhe1CaKkAvJ52nwaU3P+2ANJKtaKgRVRKfRSXCLe5aYmNG1qcEAAwY48PdX6dHDiU56uRAF2G2/vo888gidO3dm4sSJDB/+9/VFjUZDeHh4nhQnCjGXBY0jEQBVaybYFMyiEiZevGLlWGkIaLYRZ2ADLxcpCrqff9by4osmevVyMG6cHZ0OevVyerssIbLtjs/WaLVaZs6cSVBQEIqioCgKNpuNHj165FV9ohDRpp3A/9DTBBzoRejGcIptqUyxLZUxn5mBvyGAvvdPJ+n+5pg7xEtwi2xJSsoYAax3bzPXrin4+nq7IiFyVpYnjpYuXcr777+P3W7HbDZjs9no0qVLXtQmChnfE5Mwxq/PNM1aojvbHH68+r9OPF39Wbo1+M5L1YnCYsMGLaNHm7h8WUOtWhnXtqtVk2vbonDJMrzXr1/Ptm3bGDBgACtWrGDDhg1cunTprjY+ffp0Dh48iKIoTJgwgVq1annmXb58mdGjR+NwOKhWrRqvv/76ve+FyLcCDvZGm3qMtAqTSa69An3iblw+pVE1BlRDGC7VzUe/vcC2S1tpW7q9t8sVBdyff2p46ikzer3KuHE2hg+3c6N/KSEKlSy7pPL19cVgMOBwOABo06YNGzZsyHLDu3bt4vz586xatYpp06Yxbdq0TPNnzpzJs88+y5o1a9BqtXf9g0AUHAH7n8R49Rt06ScxX3gX0OIIeQC3TySqMRwVKPl+MJ/9+QkApfxKebVeUXDd+PNE1apuJk2y8dNP6YweLcEtCq8sj7wDAwNZt24dlSpVYvz48ZQvX56rV69mueHt27fTtm1bAMqXL09SUhKpqan4+fnhdrvZu3cvc+bMAeDVV1/N5m6I/EZjvYwx/gcAUiu8hqXsqJuWWXZ4sef1iw3G8kj5bnlWnygcUlLg1VeNJCfDkiWgKDBihN3bZQmR67IM71mzZnHt2jXatWvHxx9/TGxsrCd07yQ+Pp7q1at73oeEhBAXF4efnx/Xr1/H19eXGTNmcPToURo0aMCLL754x+0FB5vR6XK2J4XQUP8c3V5Rdct2XFvW89Kv4WT8brFembAIaofXpnFEY2Z3npl7BRYA8l38937+GQYMgOhoqF0bdDp/QkK8XVXBJt/D7MurNswyvFesWMGgQYMAGDz43nuSVlU10+srV67Qr18/SpUqxaBBg/j1118zPU/+/yUk5Gx/6qGh/sTFpeToNouiv9rR//AANLbLAKSXHYOj+Rl8LryLrcTjuP9fO++9spt9V/bwUJmOrOr8P0JMxYr0/wv5Lv47qakZR9srVhjQ6VTGjLEzbZqRpKQU4uK8XV3BJd/D7MuNNrzdj4Esw/vEiROcP3+e0qVL/6sPDAsLIz4+3vP+6tWrhIaGAhAcHMx9991HVFQUAE2aNOHkyZN3DG+RT7ldhGypidZ63jPJWqofKAqW0kMzLXoh+Twr/viIefveBiDQGESPyk/labmiYHO5oGNHM8ePa6la1cWCBVZq1XJjMBi9XZoQeSrL8D5+/DidO3cmMDAQvV6PqqooisKvv/56x/WaNWvGggUL6NmzJ0ePHiUsLAw/v4yTpzqdjsjISM6dO0eZMmU4evQonTt3zpEdEnnsz7c8wZ1aYQqWsqNvuVh0yoVMPagBdC73SG5XJwoZrRaefdZBbKyT0aPtGCWzRRGVZXi///7797ThevXqUb16dXr27ImiKLz66qt8+eWX+Pv7065dOyZMmMC4ceNQVZVKlSrRunXre/oc4UVuOxRvgsunDKkVp2IPv30YH7i6H62ixaW6+KjD57Qr3R69Vm4FFlnbulXLggUGPvrIgo8P9O/v8HZJQnidov7zYnQ+lhvXEeT6zr3TJe4k8EAPNI9dIu763f0xHbVpGFOaTiXQGJTL1RUs8l28tdRUmDrVyPLlBjQalU8/tdC2reuWy0obZp+0Yfbl5TXvLJ/zFuJWgne3Q+NIgAPjslx2/r53OBp/hHdaLZTgFndl+3YtrVr5sny5gcqVXfzwQ/ptg1uIokjCW/w7qorx8sq/31cbf9tFTyWcZMmh95i641VafdGUzTG/5n59osCbP99A165moqMVhg+38fPP6dStK92bCvFPWV7zttvtrF69msuXLzNmzBgOHjxIlSpVMMqdIkWS/5GBmGJXA6AqehSfcEi9+TTRH9eO0nJVk0zTHoxomRcligKuQQMXlSq5mDfPSv36EtpC3EqWR95TpkzhwoUL7Ny5E4CjR48yblzWp0pF4eQ2RQJgLdGD+Jbnb7vcjsvbPK8/aPchpwfG5HptomBKT4fXXzcQHa0A0LSpi99+S5fgFuIOsjzyPnPmDCtXrqRv374A9OrVi+++k5Gfiqq0ilNILz0M1VA803RVVZmybRLRKRfoX2MgPSr1ZMP5n1jy0MeY9WYvVSvyu507tbzwgokzZzQkJCi8844NyHgkTAhxe1keeet0GfmuKBm/itPT07FarblblciXzGfexHD1W1Bu/tqsP/c97x1cwLdnviYmJRo/gz+fdV4twS1uyWKByZONPPKID2fPKgwebGf6dJu3yxKiwMjyyLtDhw48/fTTxMTEMHXqVDZv3kyvXr3yojaRjxjifsT39FQAEhpuwhn4dyfSv5z/kad/yOgprel9D9CtYnev1CgKhqNHNQwc6MPp0xrKlnUzb56Vxo3lTnIh/o0sw7tPnz7UqlWLXbt2YTAYmDNnDjVq1MiL2kR+4bbhe3ISAKrWF2dgfc8su8tOr++e8Lz/uOPnmHSmPC9RFBxBQSrx8QrPP29n/HgbZjk5I8S/lmV49+jRg65du9K9e3eCguQZ3aJGf30LgfseRVEzOmKJbxkNQIo9mQ+PLGVMi5GsfeQb9l3Zw6DaQ/DR+XizXJFP7dunweFQaNTIRalSKjt3psoIYEJkQ5bhPXbsWH744Qe6detGlSpV6Nq1K61bt8ZgMORFfcJLFNtVFFcKLp8oUqvMxnRpBfbiHXErGn4+9wN9v38SgLpRNWke0Y7mES28XLHIj6xWeOstA4sWGYiIUNm+PQ29HgluIbIpy/CuX78+9evXZ+LEiezatYt169YxZcoUduzYkRf1CW9Q3RTfXAGA6423Y43ojzWiPwAD1/fl2zNfexY1aOVHnLi1/fs1jBhh4vhxLaVLZ1zb1kt39kLkiCzDGyA5OZlffvmF9evXEx0dzZNPPpnbdQkvMt+4MQ3A5VfF89rpdnqC+4lKPZne/E0qRERKf8giE5sNZs82sHChAZdL4dln7UyaZOPGoIJCiByQZXgPGDCAkydP0rZtWwYPHky9evXyoi7hJT5n5+B7djYAaeXGgvL3A7dWp4UJjSbza/RGFrZZ7Hl8UIh/UlX44QcdpUqpzJ1r4YEH5E5yIXJaluHdr18/mjdvjkYj3aAXBbq0E0DGXeXpZV8CYP+VvXzyx4eUDijDyPpjGFl/jDdLFPmQ3Q4HDmho2NCNyQSffGIhLEyVo20hcsltw3vq1KlMmjSJxYsX88EHH9w0/7PPPsvVwoR3pJcejst0H+nlXwFFweq00n5tKwDKBZaX4BY3OXxYw7BhJs6d07BxYxrly6uUK1cgRhoWosC6bXh3757R0cbIkSPzrBjhHdq0E4Rsa4AjsAEpVeeTXmEy6059xXsHF7L3ym7Pcl90+Z8XqxT5jd0Oc+camDvXgNOp0LevnbAwCW0h8sJtw7tKlYwblb788ktmzpyZad6AAQNo2LBh7lYmcp1iv0bItnoZ43IDP13aw2HDRlqXNdPovqacSTrNobgDONwOlrf/lKiA0l6uWOQXR45k3El+5IiWUqXczJljoVUrubYtRF65bXivW7eOlStXcvLkSXr37u2Z7nA4uHbtWp4UJ3KJ6gZFQ9Dudv/X3n2HR1Xm7x9/n5nJpBMSSEKXgCAQBalSAhGWANIUf0iCNIEvbaUKItKCQpDeIirirqyACLJRUGkqoaghgiIIrEuT3hISQupkZnJ+f4xGs5CCKWcm83ldl9c1Z+rtA+TOc86Z5+QW99JUb6bcSIVrM+l4OZbJLabJ8W2Rr5UrjZw4oWfgwGzmzDFRoYLWiYRwLvmWd+/evXniiSeYMmUK48aNy71fp9Px8MMPl0k4UcJyTHicX4wh9WfuNtlAZs2RuF9+l02VJzDla9ufsZeLNyMbj6FpgHyrQOR17ZpCtWq23eJRUSb69zfTqZPMtoXQQr7lfevWLQIDA5k/f/49j6WmpspSqQ5El3UF71PjMd7+CgBVccHlxlbO+/WiWq3RfPrlcADc9G6c/b/L6O5z1TDhvMxmiI42snSpkXXrMgkLsxIQoEpxC6GhfMt74cKFLF26lCFDhqAoCqr6x4koiqLw9ddfl0lAUXyep2flFjdA5kMv8lGqnu9OL2Rm6zm80X4xB6/s58QLZ+S72yKP//zHdmz72DE9VarkyAppQtiJfMt76dKlAOzdu7fMwoiS5ZL8LWbf92gGBgAAIABJREFUdpgCe+N289+kPL6F7MpduZWZwJh1tkMfnWqF0T2oJ8eH/FeKW+SyWGD1aiOLFxvJzlYIDzczd24WssNNCPtQ6P7R/fv3s22bbUnMyZMn06VLF/bs2VPqwcRfp5hT8PzvNCoeeQrFchezbwdSGv+LKx5NmR8/l0fX/XHOQhP/x1EUBb1OX8A7CmezYYMLUVGu+PqqbNiQQXS0FLcQ9qTQ8n7rrbdo3749+/fvJycnh08++YT169eXRTbxgHSZl6n8lS+V99XE49JbALhdfg/VWInswD6kZKfw8emPcp9/8oVz1PCuqVVcYWcsFtt/AAMGmHnpJRMHD6bTpYsc2xbC3hRa3m5ubvj5+bF//36efvppPD09ZalUO+Xx6yIU1faD1lyhOakNV5L50Hhy1ByWH1lMPd/6PP3ws2zvs5sroxLx9/DXOLGwF6dP6+jZ04M337RdJc7FBaZNy5bZthB2qtC1zU0mE++99x4HDhzglVde4cKFC6SmylWk7FFag+W4X/0XSW1/wOpZD4Bzd84w+9vpfHlxN9W8qjOn7bxC3kU4E6sV3n7bhYULXTGZFB55JAdVBTn9QQj7Vmh5z507ly1btrBgwQJcXV355ptvmDJFFu6wJ7qMc3idmUNG7fEkdE4GRc+Tm9uSlHWbG+nXc5/3zdUDhDd4XsOkwp6cPaswfrw7R47oqVw5hzVrsuje3aJ1LCFEERRa3vXq1WPIkCGcOnWKL7/8kk6dOlGtWrWyyCaKyOfYAAxpp7iccpakJhsJ8qmDu8ENd4M7tSsEYdQbmdT8ZXrWfVrrqMJOXLyo0KmTJ1lZCn36mJk/30SlSrIuuRCOotDy3rRpE2vXruWxxx5DVVUWLFjA2LFj6dOnT1nkE0WgSz/LM9dgW/pJfM90ZG7IAnb+P/mKn8jfQw+pDB5s5oknrPTqJbNtIRxNoeW9bds2du7ciaurKwAZGRkMHTpUytteWDPpdiWbLzNsm8mmZLrX6aVtJmF3rFZYu9aFkyf1REdnATBvnknjVEKIv6rQ8jYYDLnFDeDh4YGLLLNkH3LM+O8NzC3u2W3mMrbpBG0zCbtz/rzChAluxMcbqFQph+vXFapWlV3kQjiyQsu7SpUqzJ07l7Zt2wLwzTffULVq1VIPJopCIbHNYZ672Z6P72ZJcYs8cnLgvfdsi61kZir07Glm4UIT/v5S3EI4uiKdbb5+/XpiYmJQFIUmTZowaNCgssgmCqD+MpPFFw7TLXgCE7ofpPm1A1pHEnZEVaF/f3diYw34+qqsWJHJM89Y5CtgQpQTRfqe98iRI8siiygiVVUJ3LsKgHRDAK91Xk99v0c0TiXsiaJAhw4W3NxUFi0yERgos20hypN8l0o7cuQIISEhdO3alR49enDp0qWyzCUKcOT8xtzbfRpP0jCJsCcXLypMnuyK6bfz0MaMMbNuXZYUtxDlUL7lvXz5ct5//33i4+OZOXNm7lXGhLZcz86nx+6/A9DfvzqPBzTTOJHQWk4OvP++C6Ghnqxfb+TTT2071HQ6WSlNiPIq3/LW6XTUq2dbYrNNmzYkJSWVWSiRvyM5vvj/dgGwQS1e1zaM0NylSwrPPefOK6+44eICq1dn0q+ffG9biPIu32Pe/3ttZ7nWs8ZUK4oljcZBz/Pc1aO0qNWTFkG9tU4lNBQTY2DyZDfS0xW6dLGwZEkWVarILnIhnEG+5Z2SkkJcXFzu9t27d/Nst2nTpnSTiVzGhN34/PQci5KgWf3/Y07Hd7WOJOyAr6+KwQDR0bbZtvx+LYTzyLe8K1SowFtvvZW77e3tnbutKIqUdxnQmW5Q4acIEpN+JDIZVt4B4t5jqWtjBjV6Qet4ooypKmzaZKBTJytVqqh07Gjlhx/SqFBB62RCiLKWb3mvX7++LHOI+3BJOsjM8z+yKPmP+5r4N5XidkLXrilMmuRGbKyBZ54x8+67tiVOpbiFcE75nrAmtGfxbsyXVttqdl4u3qz+27t8+dx+jVOJsqSq8OGHBtq39yQ21kCnThbmzJE1yYVwdoUu0iLKns50A+XcEj5OU9g14Bcu3P2VIJ86WscSZezGDdts++uvDXh5qSxfnsXzz5vl2LYQQsrbHqnXP6Xyvnep7eZNrVrP0aJKK60jCQ2YTBAXpyc01MLy5VnUqCFnkgshbArdbX716lXGjx+fu575li1buHDhQmnnclrpd34maOdUAC5kpVLR1VfjRKIs3bihcOKE7Z/lQw+p7NmTwZYtmVLcQog8Ci3vWbNm8fTTT6Oqth8eQUFBzJo1q0hvPn/+fMLDw4mIiOD48eP3fc7SpUvlQie/yzFT/8N2pP32c/qLZ3bxsG89bTOJMqGqsGWL7dj28OHuZGba7q9fP0d2kwsh7lFoeZvNZv72t7/lLtLSsmXLIr3x999/z8WLF9m8eTNRUVFERUXd85yzZ89y+PDhB4xcTqlWDClHcNXZxvlfYWtpWa2txqFEWbh+HQYPdmfsWHfMZhgzJhs3N61TCSHsWZHONr97925ueZ85cwaTqfCzXePi4ujcuTMAdevWJSUlhbS0tDzPWbBgAZMmOfeFNZTs21Q8FIrfgYZYKrbil8E/c/WFUzxVL1zraKKUqSps3WogOBh27zYQEmJh//50XnhBTkoTQhSs0BPWXnzxRfr160dCQgK9evUiOTmZxYsXF/rGiYmJBAcH5277+fmRkJCAl5cXADExMbRq1Yrq1asXKaivrwcGg75Izy0qf3/vEn2/B3Z2LXxvu9zqkSyYu/tZZnRaQKvqjnWCmubj6KCysmDpUtuJaatXw+jRBnQ6L61jOSz5e1h8MobFV1ZjWGh5t27dmk8//ZTTp09jNBoJCgrC1dX1gT/o92PmAHfu3CEmJob333+fmzdvFun1yckZD/yZBfH39yYhIbVE3/NBVfppJjrgmAlaXgaI5VH/LwgyNtQ014Owh3F0JKpqu3Rn7dq2fw9r1ugICvLE2zuV27c1DufA5O9h8ckYFl9pjGF+vwwUWt4rV6687/0TJkwo8HUBAQEkJibmbt+6dQt/f38ADh06RFJSEgMGDCA7O5tLly4xf/58pk+fXlic8iMnG132Lf5+C95O+ePu4Y+N1C6TKFUJCQpTp7oSG2tg//50HnpIpXHjHPz9ISFB63RCCEdS6DFvvV6f+19OTg7x8fGkphb+m0W7du3YvXs3ACdPniQgICB3l3m3bt3YsWMHW7Zs4c033yQ4ONi5ihtAtZLc7PPc4q5b8WF+HHQSb6Osd1kebdtmoEMHD774woXGja1axxFCOLhCZ95jx47Ns221Whk3blyhb9ysWTOCg4OJiIhAURQiIyOJiYnB29ubsLCwv57YwekyzlHh+DAy3euQ3HAV/+79GRfu/irrlZdTiYkK06a5sn27C+7uKvPmZfF//2dGJwsTCyGK4YFXWLNYLFy6dKlIz50yZUqe7QYNGtzznBo1ajjVRVAqnBjFzaSj1LxwlPHJBka0mkf7GqFaxxKlZNYsW3G3amVh1aos6tSRxVaEEMVXaHmHhobmfk0MbNf57tOnT6mGKs8MaSfZ+NtRh1WnNvNK+7cKfoFwOBkZ4OFhuz17tommTa0MH25GX7JflhBCOLFCy/vDDz/Mva0oCl5eXlSQ6xD+NWoOu+6mM+23s4rXdlmHi95F20yiRH3xhYGpU115660sQkOtVK2qMnKkWetYQohyptAjb4sXL6Z69epUr16datWqSXEXQ/KVj+l+7Y/tLrWf0i6MKFFJSTB6tBtDh7pz967ClStyUFsIUXoKnXnXqFGDrVu30rRpU4xGY+79NWvWLNVg5ZG+QhNWPdaHT2/8h7VPf4W7wV3rSKIE7NxpYMoUVxISdDRvbmXVqizq1cvROpYQohwrtLx37Nhxz32KovD111+XSqDySjHdwtegJ6Ldu0ToHnyRG2Gftm0zMGKEO0ajyqxZJsaMycYgF9oVQpSyfH/MbN++nd69e7N3796yzFNueZ8ah2viTpLafI/V696z7oVjUVVQFOjWzcJzz5kZPz6bRx6R2bYQomzke2Bu69atZZmj/FJVvE+MxjVxJ28kQaUPWrH2+NtapxJ/0Z07MHasG2+/bTvR0NUVVq/OkuIWQpQpOaumNFnS8Pu2CW7XbWfsX8e2wpzJmq1lKvEXffmlng4dPNmyxYWdOw3kSF8LITSS727zo0eP8uSTT95zv6qqKIrCvn37SjFW+aDPvIi54hPoMy+QXGUg0Wc2AFDHp67GycSDSEmBWbPc+OgjF1xcVKZPNzF2bLaskiaE0Ey+5d2oUSOWLVtWllnKHat3MOn15pJRexJP7hiVe3+X2t00TCUexK1bCmFhHly/rqNxY9uZ5I0ayZRbCKGtfMvbaDQW+Vrb4l7+X1bA6laLlMc/xOrdmC61u/Fz4jEWh67AoJPTkR2Fv79KmzZW6tWznZTmImvqCCHsQL4t0rhx47LMUa64JH4FgD7rEjnGKgD0rd+PdtXbE1K9g5bRRBHExuo5eFDP7NnZKAq8/XYWf1ohWAghNJfvUbuXX365LHOUKx4XlgOQXakTWQYfRn85nHN3zkpx27nUVJg82ZXwcA/eecfI+fO2xpbiFkLYGznlpoS53I7FmHwQgPSHXyP+ehwxZz5m2oEphbxSaGn/fj2hoZ6sX2+kUSMru3dnyBXAhBB2S8q7hKl6T8w+LbB41sfi3ZjPzm0DwM+9ksbJRH5mznTluec8uH5d4aWXTOzZk8Fjj8lJaUII+yVnTpUgffppLD4tyQh6BbNvW1AUjtz4HoBxTSdqnE7kx89PpWFD25nkTZpIaQsh7J/MvEuKNQPfuCfwjWtJtn9XVIM3ACdv/wzAwxXra5lO/ElaGqxcacT825U6x43LZs+eDCluIYTDkJl3CVFyslBUK0rO/VdPC678aBknEvfz7bd6Jkxw49IlHV5eKsOHm+XrX0IIhyPlXcIs3o/l2f7P0F8x6PQapRG/S0+HefNc+cc/jOh0KhMmmBg40Kx1LCGE+Etkt3kJ0Zlu2G78NvM+dusorxx4icTMBHxcK2qYTMTH63nySU/+8Q8j9epZ2bEjgxkzsnGVK7MKIRyUzLxLiMfFaMC2+9yaYyVsaygA19Ov88FTm7SM5vTu3IHLlxXGjjUxdWo2bm5aJxJCiOKR8i4hmTVH4XZtI+l1Z9Drk6659y97MlrDVM4rPl5PnTo5+PurdO1qJS4unaAg+d62EKJ8kN3mJcGaicWzASmPb2ZLwmWO3LR9PWxm69eo7F5Z43DOJSMDZs1ypXdvd6ZN+2O/uBS3EKI8kfIuJmPCLvz3BuJxMZrsyl24dPciAI9VbsL4ZpM0Tudcvv9eR6dOnqxZYyQoSGXkSDkhTQhRPkl5F5PPT/0AcL/0Nih6JjafwokXzvLVcwc0TuY8MjMhMtKVXr08+PVXhVGjstm7N50nnrBqHU0IIUqFlHcx6LKu597+ofFnBK2txqofl6NX9ChyNYsyc/26wvvvu1C7tsq2bZnMnWvCw0PrVEIIUXqkvIvB7eo6ACye9Vnww1LSzWnMOxSJUS+rfpS2rCy4eNH2C1KdOiqbNmUSG5tO69Yy2xZClH9S3sVg8QoG4DPPXsSc2QrAhz0+xttYQctY5d6PP+ro3NmDgQPdycqy3deunVVm20IIpyHlXQzZgb3JCuzDj2YjAAadgb/V6qJxqvLLZIJ584x07+7B6dN6QkKs5Mhy5EIIJyTl/Re4JH6F3zdNcL22kdTG/wKd7StJG7pvlmPdpeToUdtse9UqV2rUUPnkkwzeeEOObQshnJMs0vKgLGlUPPosAC53f8RUbQADGw3hqaCeVPWqpnG48sligVGj3LlwQcfQodnMmmXCy0vrVEIIoR0p7wfkcWF57u30OtNZ8cMSGlYKpstD3WTWXcJSU8HbGwwGWLkyC7MZOnSQE9KEEELK+wG53IkDIK3+G6jGSsyPf506PnVpFtACfw9/jdOVD9nZsGyZkXXrXNi7N4Nq1VTatJHSFkKI38kx7wek6j0ByPYLzb3vfMo5Ke4S8vPPOrp08WDZMlfc3eHmTdmbIYQQ/0tm3g8oI2gy2f7dsbjX5asLu7SOU25kZ8OKFUZWrDBisSgMGpTNnDkmvL21TiaEEPZHyvtBWLPIcXuIrIqtOZF4nAE7bEujBngEahzM8c2a5cr77xupVi2HZcsy6dRJdpMLIUR+pLwfgNvVf2FI/RlT4DOoamUa+jVCUXT8u/dnWkdzSKoKv5/j9+KL2agqzJxpooKscSOEEAWS8i4qNQfv/74MwFljfajYgf0RhzQO5bhOndIxcaIbr79uonVrK7VqqSxaZNI6lhBCOAQ5Ya2IXG9+mnt76plviL30NWnmNA0TOSaLBZYvNxIW5sFPP+nZt0+vdSQhhHA4Ut5FVOHnFwA45tODXRd2ERX/GiaLzBQfxC+/6Oje3YM33nClUiWVjRszmDYtW+tYQgjhcKS8i8Kanntzs9og93Yl90papHFIBw7o6dzZNtvu18/MgQPphIXJSWlCCPFXyDHvolCMJLfcg86cwskfPwRgSehKjUM5lhYtrLRoYWXMmGy6dpXSFkKI4pDyLgpFh8WnJSnZqWw/9xwAtX2CNA5l3ywWePttIz4+KoMHm/HwgE8/zdQ6lhBClAtS3kXg8+Oz5Lj4kfHISj7utY1PzmylffXQwl/opM6c0TF+vBs//KCndu0c+vc34+KidSohhCg/pLyLwJgUS4IFFqfVILLtXEJrdtQ6kl2yWuGdd1xYsMAVk0nh2WfNzJ+fJcUthBAlrFTLe/78+Rw7dgxFUZg+fTqNGzfOfezQoUMsW7YMnU5HUFAQUVFR6HR2eP5cjhmAZXdg9a8rCanenr891EXjUPbn7l2IiPDgyBE9lSvn8M47WfToYdE6lhBClEul1pbff/89Fy9eZPPmzURFRREVFZXn8dmzZ7Nq1So++ugj0tPTOXjwYGlFKRav09NItsKCZNv28YRj2gayU97e4Oen8swzZg4ezJDiFkKIUlRqM++4uDg6d+4MQN26dUlJSSEtLQ0vLy8AYmJicm/7+fmRnJxcWlGKxSX5Ozpe+2N7VJMXtQtjZ86fV1i/HgYNsi1z+t57mbi5aZ1KCCHKv1KbeScmJuLr65u77efnR0JCQu7278V969Ytvv32W0JD7fMEMIv3Y8Rn2W5/E3EYDxcPbQPZgZwcePddFzp29GTyZDh+3PbXSIpbCCHKRpmdsKaq6j333b59m9GjRxMZGZmn6O/H19cDg6Fkl9L09y/C9SY7buJfPh0Z8tko2j3SokQ/3xGdPQvDhsHBg1CpEqxbB3/7m6fWsRxekf4uigLJGBafjGHxldUYllp5BwQEkJiYmLt969Yt/P39c7fT0tIYMWIEEydOJCQkpND3S07OKNF8/v7eJCSkFvicfQee5qpbA55qPJXtz+wq9Pnl3fvvu/Daa65kZCj06GFm4UITwcFeTj8uxVWUv4uiYDKGxSdjWHylMYb5/TJQarvN27Vrx+7duwE4efIkAQEBubvKARYsWMCQIUPo0KFDaUUoFsu1f9PvRCwf/vw2Z5PP0rpaW60jae7GDQVXV1izJpN//jOLgIB796YIIYQofaU2827WrBnBwcFERESgKAqRkZHExMTg7e1NSEgIn376KRcvXmTr1q0A9OzZk/Dw8NKK88BW7x8KwGETNA1opnEabeTkwPbtBnr1sqDXw0svZTN8uFlKWwghNFaqx7ynTJmSZ7tBgz8u6nHixInS/Ohi0af9Qs5vt+e2no2L3vlWGbl0SWHiRDe++cbAa69lMWaMGVdXpLiFEMIO2OGqKNrzPjWOuN/OMG8U0FLbMGVMVWHdOhdCQz355hsDXbtaePZZ+c62EELYEynv+0hrsIhqXjUAqOldS+M0ZefyZYW+fd2ZOtUNgwHefDOTDz7IJDBQZttCCGFPZG3z+8j0aMTQ0I10SbtKgEeg1nHKzE8/6Tl40EBYmIWlS7OoUkVKWwgh7JGU9/9YuqkCJy0ejA9ZRfc6/bSOU+quXlXw8FDx9YVevSzExGTQrp0VRdE6mRBCiPzIbvM/0aeeYGEyfJ6awY7rP2kdp1SpKmzc6EKHDp68+uofS6OFhEhxCyGEvZOZ95/os67k3p7edr6GSUrXtWsKL73kxt69Bry9VTp0sKCqSGkLIYSDkPL+kxN3LgJQ1bV8LhGoqvDRRwZmznQjNVWhY0cLy5ZlUb26HNsWQghHIuX9Jxt/2QhADXcfjZOUjkuXFF5+2Q2jEZYty2LAALPMtoUQwgFJef9JozoDefTmTyxtOV7rKCVGVeHOHfD1hYceUlm9Oovmza3UqCGzbSGEcFRS3n8SHjyS52t3xOpZT+soJeLGDYUpU9y4dk1h164MjEZ4+mlZcEUIIRydnG3+G8vtg1w4NZcbWSlaRyk2VYWPPzbQoYMne/YY8PVVSU2V/eNCCFFeSHn/5sK1XbTat5g3D03TOkqx3LypMGSIGy++6E52NixalMXWrZlUqiS7yYUQoryQ3ea/SToXDYDVpaLGSf46VYXwcHdOndITEmJh+fIsHnpISlsIIcobKW9AsdxlcoLt9h3VreAn2yGrFfR62/e0Z8828euvOoYONaOT/SpCCFEuyY93AGsWvx8RHtJknKZRHoSqwiefGAgJ8eTmTdv/QadOVoYPl+IWQojyTH7EAy63Y/nFbBuMllWe0DpOkSQkKAwf7saoUe5cu6Zw/Lj8UQohhLOQ3eZAql9H5j0+nPik81pHKZLt2w288oort2/reOIJCytXZlGnjhzbFkIIZyHlDbi6BTCy7XJGah2kCJYtM7JggSvu7ipz52YxYoTsIhdCCGcjP/aB92P788PhMaSZ07SOUqhnnjHToYOFvXvTGTVKilsIIZyR/OgHXvnPFzx1eCMXUn7VOso9kpJg9Gg3fvjB9kdVp47K1q2Z1K0ru8mFEMJZOf1u88Q025XE/PXwaOXHNE6T1xdfGHj5ZVcSE3Xo9dC8eZbWkYQQQtgBpy/vS3dOA2Cxo50QSUkwfbobMTEuuLqqzJ6dxZgxZq1jCSGEsBNOX97Kb9/wfqFKXY2T2Pz8s47+/d25dUtH8+ZWVq7Mon79HK1jCSGEsCNOX95xF7YBkKNaNU5iExSUg4+PyqhRJsaMycbg9H9CQggh/pfTV0OXoF5Y00/j51lTswx79uhJT1fo08eClxfs25eBi4tmcYQQQtg5py/vh6t3YURgB9wMZb+m+Z07MHOmG1u2uFCpUg5du1rw8ECKWwghRIHs5ywtjWw6MIifTr9jWyi8DH31lZ4OHTzZssWFJk2sxMRk4uFRphGEEEI4KKeeeZusJiac2AZsI7FOP3LcqpX6Z2ZlwSuvuLFpkwsuLirTppkYNy5bZttCCCGKzKnL+2bqFQCMCuQYK5XJZ7q6wrVrCo8+aiU6OovgYDmTXAghxINx6vJO+6YtAM1dAZ1rqX1Oaip89ZWBPn0sKAqsWZOJt7cc2xZCCPHXOHV5703LBOCJoOdK7TP27dMzaZIbV6/qqF49nVatcvDzK7WPE0II4QSc+oS1jRmeAFTxb13i752WBpMnu9Kvnwc3bypMnmzi8cdlF7kQQojic+qZd/STy/jivxsY0HBwib7vgQO22fblyzoaNrQd227cWIpbCCFEyXDq8m5Zqyct6vQv8ffdu9fAtWsKL71k4qWXsjEaS/wjhBBCODGn3W3+1ZFFzNrVm5/PfVAi73f0qI6c3ybXr7xiYs+eDKZNk+IWQghR8py2vD89u4d3Lv3AnrMfFet90tJg2jRXunb15J//tJ0+7u4Ojz0mu8mFEEKUDqfdbf7JpR8AaBvY7C+/x3ff6Rk/3o1Ll3Q88oiV5s3t4+ImQgghyjenLe9Mq+362I9VqPHAr01Ph/nzXVm71ohOpzJunImXX87GreyXRxdCCOGEnLa8K7i4kZydTiVXL0wP+Nqvvzawdq2RevWsrFqVRfPmsotcCCFE2XHa8saSwUMGUIp4He+MDMjJAS8v6NXLwqpVmTzzjEVm20IIIcqc056wNqvx08wI8Mbs27bQ58bH6+nUyZOZM21LqCoKRERIcQshhNCG0868h3ffREJCKgXNuzMz4Y03XFmzxnYWebduttm3zml/5RFCCGEPnLK8r6de5di5zVSp8jyBnlXu+5zDh3WMH+/OuXM66tTJYeXKLJ54Qs4mF0IIoT2nnEMeOLWUsN1zOBzb6b6P37yp8OyzHpw/rzBqVDZ796ZLcQshhLAbTjnz1lltVxOzegTlud9stl2mMzBQ5bXXTDRqlEPr1lLaQggh7ItTlvfvrB51AcjKgkWLjBw6ZGD79gwMBhg2zKxxOiGEEOL+SnW3+fz58wkPDyciIoLjx4/neey7776jb9++hIeHs3r16tKMUaCjR3V07uzBm2+6kpCgcO2aolkWIYQQoihKrby///57Ll68yObNm4mKiiIqKirP4/PmzSM6OppNmzbx7bffcvbs2dKKcn8WI59+8P946ikPTp/WM3x4Nvv2pVOrllq2OYQQQogHVGq7zePi4ujcuTMAdevWJSUlhbS0NLy8vLh8+TI+Pj5UrVoVgNDQUOLi4nj44YdLK869Nn7Brl87U6tWDitWZBISIse2hRBCOIZSK+/ExESCg4Nzt/38/EhISMDLy4uEhAT8/PzyPHb58uUC38/X1wODQV8i2Z5rP4PU8df57/FkVq3yxcvLo0Te11n5+3trHcHhyRgWn4xh8ckYFl9ZjWGZnbCmqsXbHZ2cnFFCSQBq8MrEhiQkpJKZmUpmZgm+tZPx9/cmISFV6xgOTcaw+GQMi0/GsPhKYwzz+2Wg1I55BwQEkJiYmLt969Yt/P397/vYzZs3CQgIKK0oQgghRLlSauXdrl07du/eDcDJkycJCAjAy8sLgBo1apCcSnWrAAALg0lEQVSWlsaVK1ewWCzExsbSrl270ooihBBClCulttu8WbNmBAcHExERgaIoREZGEhMTg7e3N2FhYcyZM4fJkycD0L17d4KCggp5RyGEEEIAKGpxD0aXkdI4jiDHd4pPxrH4ZAyLT8aw+GQMi69cHPMWQgghROmQ8hZCCCEcjJS3EEII4WCkvIUQQggHI+UthBBCOBgpbyGEEMLBSHkLIYQQDkbKWwghhHAwDrNIixBCCCFsZOYthBBCOBgpbyGEEMLBSHkLIYQQDkbKWwghhHAwUt5CCCGEg5HyFkIIIRyMU5T3/PnzCQ8PJyIiguPHj+d57LvvvqNv376Eh4ezevVqjRLav4LG8NChQ/Tr14+IiAheffVVcnJyNEpp3woaw98tXbqUQYMGlXEyx1HQGF6/fp3+/fvTt29fZs+erVFCx1DQOG7cuJHw8HD69+9PVFSURgnt3+nTp+ncuTMbNmy457Ey6RW1nIuPj1dHjhypqqqqnj17Vu3Xr1+ex5966in12rVrqtVqVfv376+eOXNGi5h2rbAxDAsLU69fv66qqqqOGzdO3bdvX5lntHeFjaGqquqZM2fU8PBwdeDAgWUdzyEUNobjx49X9+zZo6qqqs6ZM0e9evVqmWd0BAWNY2pqqtqxY0fVbDarqqqqQ4cOVY8ePapJTnuWnp6uDhw4UJ05c6a6fv36ex4vi14p9zPvuLg4OnfuDEDdunVJSUkhLS0NgMuXL+Pj40PVqlXR6XSEhoYSFxenZVy7VNAYAsTExFClShUA/Pz8SE5O1iSnPStsDAEWLFjApEmTtIjnEAoaw5ycHH744Qc6deoEQGRkJNWqVdMsqz0raBxdXFxwcXEhIyMDi8VCZmYmPj4+Wsa1S0ajkbVr1xIQEHDPY2XVK+W+vBMTE/H19c3d9vPzIyEhAYCEhAT8/Pzu+5j4Q0FjCODl5QXArVu3+PbbbwkNDS3zjPausDGMiYmhVatWVK9eXYt4DqGgMUxKSsLT05M33niD/v37s3TpUq1i2r2CxtHV1ZUXX3yRzp0707FjR5o0aUJQUJBWUe2WwWDAzc3tvo+VVa+U+/L+X6qsBlts9xvD27dvM3r0aCIjI/P8YBD39+cxvHPnDjExMQwdOlTDRI7nz2Ooqio3b95k8ODBbNiwgVOnTrFv3z7twjmQP49jWloaa9asYdeuXXz99dccO3aMX375RcN0Ij/lvrwDAgJITEzM3b516xb+/v73fezmzZv33Q3i7AoaQ7D9gx8xYgQTJ04kJCREi4h2r6AxPHToEElJSQwYMICxY8dy8uRJ5s+fr1VUu1XQGPr6+lKtWjVq1aqFXq+nTZs2nDlzRquodq2gcTx37hw1a9bEz88Po9FIixYtOHHihFZRHVJZ9Uq5L+927dqxe/duAE6ePElAQEDubt4aNWqQlpbGlStXsFgsxMbG0q5dOy3j2qWCxhBsx2qHDBlChw4dtIpo9woaw27durFjxw62bNnCm2++SXBwMNOnT9cyrl0qaAwNBgM1a9bkwoULuY/L7t77K2gcq1evzrlz58jKygLgxIkT1K5dW6uoDqmsesUpriq2ZMkSjhw5gqIoREZGcurUKby9vQkLC+Pw4cMsWbIEgC5dujB8+HCN09qn/MYwJCSEli1b0rRp09zn9uzZk/DwcA3T2qeC/h7+7sqVK7z66qusX79ew6T2q6AxvHjxItOmTUNVVerXr8+cOXPQ6cr9/OQvKWgcP/roI2JiYtDr9TRt2pSpU6dqHdfunDhxgoULF3L16lUMBgOBgYF06tSJGjVqlFmvOEV5CyGEEOWJ/FoqhBBCOBgpbyGEEMLBSHkLIYQQDkbKWwghhHAwUt5CCCGEgzFoHUAIZ3DlyhW6deuW5yt1ANOnT6dhw4b3fU10dDQWi6VY653Hx8fz97//nUaNGgFgMplo1KgRM2bMwMXF5YHe68CBA5w8eZIxY8bw448/4u/vT82aNYmKiuLpp5/m0Ucf/cs5o6OjiYmJoUaNGgBYLBaqVKnC66+/jre3d76vu3nzJufPn6dNmzZ/+bOFcERS3kKUET8/P02+v12/fv3cz1VVlUmTJrF582YGDhz4QO/ToUOH3IV4YmJi6N69OzVr1mTGjBklkrN37955flFZvHgx77zzDi+//HK+r4mPj+fcuXNS3sLpSHkLobFz584RGRmJXq8nLS2NiRMn0r59+9zHLRYLM2fO5Ndff0VRFBo2bEhkZCTZ2dm8/vrrXLx4kfT0dHr27MmwYcMK/CxFUWjevDnnz58HYN++faxevRo3Nzfc3d2ZO3cugYGBLFmyhEOHDmE0GgkMDGThwoV8/vnnfPfdd3Tt2pVdu3Zx/PhxXn31Vd566y3GjBnD0qVLmTFjBs2aNQPghRdeYOjQodSrV4/XXnuNzMxMMjIyeOmll2jbtm2h49K0aVO2bNkCwJEjR1iyZAlGo5GsrCwiIyOpUKECK1asQFVVKlasyIABAx54PIRwVFLeQmgsMTGRCRMm0LJlS44ePcrcuXPzlPfp06c5duwYO3fuBGDLli2kpqayefNmAgICmDdvHlarlX79+tG2bVsaNGiQ72eZTCZiY2Pp27cvmZmZzJw5k61bt1KlShU2bNjAihUrmDZtGhs3buTIkSPo9Xp27NiRZ63msLAwPvjgA8aMGUObNm146623AOjVqxe7d++mWbNm3L59m3PnzhESEsKYMWMYNmwYrVu3JiEhgfDwcPbs2YPBkP+PH4vFwueff87jjz8O2C7eMmfOHBo0aMDnn3/OmjVrWLVqFX369MFisTB06FDee++9Bx4PIRyVlLcQZSQpKYlBgwbluW/lypX4+/uzaNEili9fjtls5s6dO3meU7duXXx9fRkxYgQdO3bkqaeewtvbm/j4eG7cuMHhw4cByM7O5tKlS/eU1enTp/N8bseOHenevTv/+c9/qFSpUu612Fu1asVHH32Ej48P7du3Z+DAgYSFhdG9e/fc5xSkR48e9O/fn1dffZVdu3bRrVs39Ho98fHxpKens3r1asC2Dvnt27cJDAzM8/rt27fz448/oqoqp06dYvDgwYwcORKAypUrs2jRIkwmE6mpqfe9xnRRx0OI8kDKW4gykt8x78mTJ9OjRw/69u3L6dOnGT16dJ7HXV1d+fDDDzl58mTurHnTpk0YjUZefPFFunXrVuDn/vmY958pipJnW1XV3PtWrVrFuXPn2L9/PwMHDiQ6OrrQ/7/fT2A7fvw4O3fuZNq0aQAYjUaio6PzXOP4fv58zHv06NFUr149d3Y+depUXnvtNdq0aUNsbCz//Oc/73l9UcdDiPJAviomhMYSExOpV68eADt27CA7OzvP4z///DOffPIJwcHBjB07luDgYC5cuEDz5s1zd6Xn5OTwxhtv3DNrL0jt2rW5ffs2165dAyAuLo4mTZpw+fJl1q1bR926dRk2bBhhYWH3XNNZURTMZvM979mrVy+2bt1KSkpK7tnnf86ZlJREVFRUodkiIyOJjo7mxo0becbIarWya9eu3DFSFAWLxXLP5/yV8RDCkUh5C6GxYcOGMXXqVIYPH07z5s3x8fFhwYIFuY/XqlWL3bt3ExERweDBg6lQoQLNmjVjwIABeHh4EB4eTr9+/fD29qZixYpF/lw3NzeioqKYNGkSgwYNIi4ujokTJxIYGMipU6fo27cvQ4YM4erVq3Tp0iXPa9u1a0dkZCR79uzJc3+XLl347LPP6NGjR+59M2bM4KuvvuL5559n5MiRtG7dutBsVatWZcSIEcyaNQuAESNGMGTIEEaPHk2fPn24fv0669ato0WLFsTExLBixYpij4cQjkSuKiaEEEI4GJl5CyGEEA5GylsIIYRwMFLeQgghhIOR8hZCCCEcjJS3EEII4WCkvIUQQggHI+UthBBCOBgpbyGEEMLB/H/PXfZ6L4wJHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYYm52Yduosv"
      },
      "source": [
        "roc = {label: [] for label in multi_class_series.unique()}\n",
        "for label in multi_class_series.unique():\n",
        "    selected_classifier.fit(train_set_dataframe, train_class == label)\n",
        "    predictions_proba = selected_classifier.predict_proba(test_set_dataframe)\n",
        "    roc[label] += roc_auc_score(test_class, predictions_proba[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3G7EU_Hsh3X",
        "outputId": "e5d1dfb4-aefe-41c8-8739-b4653c806216"
      },
      "source": [
        "y[1]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLf99h2IsWuG"
      },
      "source": [
        "n_classes = 5"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "9S2scudZnBWD",
        "outputId": "f3d4a4ee-4826-491c-c58c-bbac5cfd6aa4"
      },
      "source": [
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate( y_test for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-621f3a8d933a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9NCYnjZrd2P"
      },
      "source": [
        "confusion_metrics(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUqL7rbGBlQa"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVv6GyeBjM2"
      },
      "source": [
        "filename = 'Random Forest.sav'\n",
        "pickle.dump(rfc, open(filename, 'wb'))"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnnI9IYCTmZ"
      },
      "source": [
        "filename = 'XGBoost.sav'\n",
        "pickle.dump(xg, open(filename, 'wb'))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqH3JdpDpO9s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}